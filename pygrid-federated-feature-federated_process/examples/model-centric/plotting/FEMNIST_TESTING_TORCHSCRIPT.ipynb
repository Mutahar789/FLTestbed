{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fda4ab04810>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import syft as sy\n",
    "from syft.serde import protobuf\n",
    "from syft_proto.execution.v1.plan_pb2 import Plan as PlanPB\n",
    "from syft_proto.execution.v1.state_pb2 import State as StatePB\n",
    "from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient\n",
    "from syft.execution.state import State\n",
    "from syft.execution.placeholder import PlaceHolder\n",
    "from syft.frameworks.torch.tensors.interpreters.autograd import AutogradTensor\n",
    "from syft.execution.translation import TranslationTarget\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from websocket import create_connection\n",
    "import websockets\n",
    "import json\n",
    "import requests\n",
    "from functools import reduce\n",
    "\n",
    "sy.make_hook(globals())\n",
    "hook.local_worker.framework = None # force protobuf serialization for tensors\n",
    "th.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTensorSum(tensor, tensorName):\n",
    "  print(tensorName, 'sum:', tensor.sum())\n",
    "\n",
    "def printTensorArraySum(tensorArray, tensorArrayName):\n",
    "    sumTensorArray = [tensor.sum() for tensor in tensorArray]\n",
    "    print(tensorArrayName, 'sum:', sum(sumTensorArray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(modelParams, filePath):\n",
    "  params = [param.detach().numpy() for param in modelParams]\n",
    "  np.save(filePath , params, allow_pickle=True)\n",
    "\n",
    "def load_model(model, filePath):\n",
    "  np_params = np.load(filePath, allow_pickle=True)\n",
    "  model_params = [param.data.copy_(th.from_numpy(np_params[i])) for i, param in enumerate(model.parameters())]\n",
    "  \n",
    "modelPath = 'modelFemnistSavedParams.npy'\n",
    "modelPath187 = 'weights_for_round_187.npy'\n",
    "modelPath188 = 'weights_for_round_188.npy'\n",
    "modelPath1 = 'weights_for_round_1.npy'\n",
    "modelPathForPruning = 'pytorch_weights_1549775860.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_model(filePath):\n",
    "    th_np_params = np.load(filePath, allow_pickle=True)\n",
    "    tf_np_params = []\n",
    "    for i, param in enumerate(th_np_params):\n",
    "        if i % 2 != 0:\n",
    "            tf_np_params.append(param)\n",
    "        elif i == 0 or i == 2:\n",
    "            tf_np_params.append(param.transpose(2, 3, 1, 0))\n",
    "        else:\n",
    "            tf_np_params.append(param.transpose())\n",
    "\n",
    "    return tf_np_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_custom_tensor(tensor, filePath):\n",
    "    np_tensor = tensor.detach().numpy()\n",
    "    np.save(filePath, np_tensor.child.child, allow_pickle=True)\n",
    "    \n",
    "def load_custom_tensor(filePath):\n",
    "    torchTensor = th.tensor(np.load(filePath, allow_pickle=True), requires_grad=True)\n",
    "    placeHolderTensor = PlaceHolder().on(torchTensor, wrap=False)\n",
    "    return AutogradTensor().on(placeHolderTensor, wrap=False)\n",
    "\n",
    "def load_tensor(filePath):\n",
    "    return th.tensor(np.load(filePath, allow_pickle=True), requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Syft models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_model_params(module, params_list, start_param_idx=0):\n",
    "    \"\"\" Set params list into model recursively\n",
    "    \"\"\"\n",
    "    param_idx = start_param_idx\n",
    "\n",
    "    for name, param in module._parameters.items():\n",
    "        module._parameters[name] = params_list[param_idx]\n",
    "        param_idx += 1\n",
    "\n",
    "    for name, child in module._modules.items():\n",
    "        if child is not None:\n",
    "            param_idx = set_model_params(child, params_list, param_idx)\n",
    "\n",
    "    return param_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_softmax(x): ##computes softmax of a given value of x\n",
    "#     xExp = x.exp()\n",
    "    return x.exp()/x.exp().sum(dim = 1, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 10\n",
    "CLASSES = 5\n",
    "# th.set_default_dtype(th.float64)\n",
    "class FemnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FemnistNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2) ##output shape (batch, 32, 28, 28)\n",
    "#         th.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "#         th.nn.init.kaiming_uniform(self.conv1.weight)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ) ## output shape (batch, 32, 14, 14)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2) ##output shape (batch, 64, 14, 14)\n",
    "#         th.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "#         th.nn.init.kaiming_uniform(self.conv2.weight)\n",
    "\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2) ## output shape (batch, 64, 7, 7)\n",
    "        \n",
    "        self.fc1 = nn.Linear(3136, 2048)\n",
    "#         th.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "#         th.nn.init.kaiming_uniform(self.fc1.weight)\n",
    "\n",
    "        \n",
    "        self.fc2 = nn.Linear(2048 ,62)\n",
    "#         th.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "#         th.nn.init.kaiming_uniform(self.fc2.weight)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         printTensorSum(x, 'INPUT')\n",
    "#         print('INPUT SHAPE:', x.shape)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = th.nn.functional.relu(x)\n",
    "        \n",
    "#         printTensorSum(x, 'CONV1')\n",
    "#         save_custom_tensor(x, 'conv1_pysyft.npy')\n",
    "\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x=self.conv2(x)\n",
    "        x = th.nn.functional.relu(x)\n",
    "        \n",
    "#         printTensorSum(x, 'CONV2')\n",
    "#         save_custom_tensor(x, 'conv2_pysyft.npy')\n",
    "        \n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        l1_activations = th.nn.functional.relu(x)\n",
    "#         save_custom_tensor(l1_activations, 'linear1_pysyft.npy')\n",
    "        \n",
    "        \n",
    "#         printTensorSum(l1_activations, 'FC1')\n",
    "        \n",
    "        x = self.fc2(l1_activations)\n",
    "        \n",
    "#         printTensorSum(x, 'FC2')\n",
    "\n",
    "# #         x = x.softmax()\n",
    "#         save_custom_tensor(x, 'linear2_pysyft.npy')\n",
    "\n",
    "\n",
    "        return x, l1_activations\n",
    "    \n",
    "\n",
    "# th.set_default_dtype(th.float64)\n",
    "class FemnistNetSmall(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FemnistNetSmall, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2) ##output shape (batch, 32, 28, 28)\n",
    "#         th.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2) ## output shape (batch, 32, 14, 14)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2) ##output shape (batch, 64, 14, 14)\n",
    "#         th.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        \n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2) ## output shape (batch, 64, 7, 7)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1568, 1024) ##input of [BatchSize, 3136]. output of [BatchSize, 2048]\n",
    "#         th.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "        self.fc2 = nn.Linear(1024 ,62) ##input of [BatchSize, 2048]. output of [BatchSize, 62]\n",
    "#         th.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28) ##reshape 1D array to 3D image to be passed to conv2d layer\n",
    "        \n",
    "        x = self.conv1(x) ##apply first convolution operation \n",
    "        x = th.nn.functional.relu(x) ##apply relu\n",
    "\n",
    "        x = self.pool1(x) ##first pooling layer\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x = th.nn.functional.relu(x)\n",
    "\n",
    "        x = self.pool2(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        \n",
    "        x = self.fc1(x) ##apply first linear layer operation\n",
    "        l1_activations = th.nn.functional.relu(x)\n",
    "        \n",
    "        \n",
    "        x = self.fc2(l1_activations)\n",
    "#         x = x.softmax() ##apply softmax on output of second dense layer\n",
    "\n",
    "        return x, l1_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_with_logits(log_logits, targets, batch_size):\n",
    "    eps = PlaceHolder().on(th.tensor(1e-7), wrap = False)\n",
    "    return -(targets * th.log(log_logits + eps)).sum() / batch_size\n",
    "#     return -(targets * log_logits).sum() / batch_size\n",
    "\n",
    "def softmax_cross_entropy_with_logits(logits, targets, batch_size):\n",
    "    \"\"\" Calculates softmax entropy\n",
    "        Args:\n",
    "            * logits: (NxC) outputs of dense layer\n",
    "            * targets: (NxC) one-hot encoded labels\n",
    "            * batch_size: value of N, temporarily required because Plan cannot trace .shape\n",
    "    \"\"\"\n",
    "    # numstable logsoftmax\n",
    "    norm_logits = logits - logits.max(dim = 1, keepdim = True)[0]\n",
    "    log_probs = norm_logits - norm_logits.exp().sum(dim=1, keepdim=True).log()\n",
    "    \n",
    "    # NLL, reduction = mean\n",
    "    return -(targets * log_probs).sum() / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainFile1500 = 'data_custom/single_format/train/client_train_1500.json'\n",
    "# testFile250 = 'data_custom/single_format/test/client_test_250.json'\n",
    "\n",
    "# trainFile500 = 'data_custom/single_format/train/slow_client_train_500.json'\n",
    "# testFile150 = 'data_custom/single_format/test/slow_client_test_150.json'\n",
    "\n",
    "trainFile = 'sample.json'\n",
    "testFile = 'sample_test.json'\n",
    "\n",
    "# trainFile1 = 'data_custom/single_format/train/debug_testbed.json'\n",
    "# testFile1 = 'data_custom/single_format/test/debug_testbed_test.json'\n",
    "\n",
    "# trainFile2 = 'data_custom/single_format/train/debug_testbed2.json'\n",
    "# testFile2 = 'data_custom/single_format/test/debug_testbed2_test.json'\n",
    "\n",
    "femnistUser = {}\n",
    "with open(trainFile, 'r') as f:\n",
    "    femnistUser = json.load(f)\n",
    "\n",
    "emnistUser = {}\n",
    "with open(testFile, 'r') as f:\n",
    "    femnistUserTest = json.load(f)\n",
    "\n",
    "\n",
    "dataX = np.array(femnistUser['x'])\n",
    "dataY = np.array(femnistUser['y'])\n",
    "\n",
    "dataX_test = np.array(femnistUserTest['x'])\n",
    "dataY_test = np.array(femnistUserTest['y'])\n",
    "\n",
    "X = th.tensor(dataX, dtype=th.float)\n",
    "y = nn.functional.one_hot(th.tensor(dataY), 62)\n",
    "\n",
    "\n",
    "X_test = th.tensor(dataX_test, dtype=th.float)\n",
    "y_test = nn.functional.one_hot(th.tensor(dataY_test), 62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining syft training plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sgd(param, **kwargs):\n",
    "    return param - kwargs['lr'] * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = th.tensor([20])\n",
    "lr = th.tensor([0.0003])\n",
    "\n",
    "model = FemnistNet()\n",
    "# np_params = np.load('params.npy', allow_pickle=True)\n",
    "\n",
    "# model_params = [param.data.copy_(th.from_numpy(np_params[i])) for i, param in enumerate(model.parameters())]\n",
    "\n",
    "# load_model(model, modelPath)\n",
    "model_params = [param.data for param in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_over_examples(activations, total_examples):\n",
    "    reduced_sum = th.sum(activations, dim=0)#reduce(th.add, activations)\n",
    "    return th.div(reduced_sum, total_examples)\n",
    "\n",
    "@sy.func2plan()\n",
    "def training_plan(X, y, batch_size, lr, model_params):\n",
    "    model = FemnistNet() \n",
    "    model.float()\n",
    "    model.train()\n",
    "    \n",
    "    # inject params into model\n",
    "    \n",
    "#     printTensorArraySum(model_params, 'MODEL_PARAMS')\n",
    "    set_model_params(model, model_params)\n",
    "    \n",
    "    \n",
    "    logits, activations = model.forward(X)\n",
    "    loss = softmax_cross_entropy_with_logits(logits, y, batch_size)\n",
    "\n",
    "    \n",
    "    #     loss = cross_entropy_with_logits(logits, y, batch_size)\n",
    "    \n",
    "    save_custom_tensor(loss, 'loss_pysyft.npy')\n",
    "    \n",
    "        \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    print('Batch size after backpass:', batch_size)\n",
    "    \n",
    "    param_gradients = [param.grad for param in model.parameters()]\n",
    "    \n",
    "#     print(\"Logits:\", logits)\n",
    "    \n",
    "#     for i, param_gradient in enumerate(param_gradients):\n",
    "#         print(\"Shape:\", param_gradient.shape, \"Sum:\", param_gradient.sum().child.data)\n",
    "    \n",
    "\n",
    "    updated_params = [\n",
    "        naive_sgd(param, lr=lr)\n",
    "        for param in model_params\n",
    "    ]\n",
    "\n",
    "    # accuracy\n",
    "    pred = th.argmax(logits, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    acc = pred.eq(target).sum()/ batch_size\n",
    "    \n",
    "    print(\"Acc:\", acc)\n",
    "    \n",
    "    avg_act_over_examples = get_average_over_examples(activations, list(X.shape)[0])\n",
    "    \n",
    "    \n",
    "    return (\n",
    "        loss,\n",
    "        acc,\n",
    "        logits,\n",
    "        avg_act_over_examples,\n",
    "        *updated_params,        \n",
    "    )\n",
    "\n",
    "\n",
    "@sy.func2plan()\n",
    "def training_plan_small(X, y, batch_size, lr, model_params):\n",
    "    model = FemnistNetSmall() \n",
    "    model.train()\n",
    "    \n",
    "    # inject params into model\n",
    "    set_model_params(model, model_params)\n",
    "    \n",
    "    \n",
    "    logits, activations = model.forward(X)\n",
    "    \n",
    "#     loss = cross_entropy_with_logits(logits, y, batch_size)\n",
    "    loss = softmax_cross_entropy_with_logits(logits, y, batch_size)\n",
    "        \n",
    "        \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "    \n",
    "\n",
    "    updated_params = [\n",
    "        naive_sgd(param, lr=lr)\n",
    "        for param in model_params\n",
    "    ]\n",
    "    \n",
    "    # accuracy\n",
    "    pred = th.argmax(logits, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    acc = pred.eq(target).sum()/ batch_size\n",
    "    \n",
    "    print(\"Acc:\", acc)\n",
    "    \n",
    "    avg_act_over_examples = get_average_over_examples(activations, list(X.shape)[0])\n",
    "    \n",
    "    return (\n",
    "        loss,\n",
    "        acc,\n",
    "        logits,\n",
    "        avg_act_over_examples,\n",
    "        *updated_params,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size after backpass: AutogradTensor>PlaceHolder[Id:96468674254]>tensor([10.])\n",
      "Acc: AutogradTensor>PlaceHolder[Id:21008175216]>tensor([0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutogradTensor>PlaceHolder[Id:79807912222]>tensor([18.61926651])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FemnistNet() ##model\n",
    "\n",
    "\n",
    "# print(model_params)\n",
    "# [print(model_param.shape) for model_param in model_params]\n",
    "\n",
    "num = 10\n",
    "X = th.tensor((dataX), dtype=th.float) ##784 sized 1D array. would be reshaped to 1, 28, 28\n",
    "y = nn.functional.one_hot(th.tensor(dataY), 62) ##62-length sized one hot vectors\n",
    "\n",
    "lr = th.tensor([0.0003]) ##0.0003 learning rate\n",
    "batch_size = th.tensor([float(num)]) ##20 is our batch size\n",
    "\n",
    "loss, acc, logits, target, *updated_params, _ = training_plan.build(X[0:num], y[0:num], batch_size, lr, model_params, trace_autograd=True)\n",
    "# updated_params\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: AutogradTensor>PlaceHolder[Id:41590466556]>tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "model_small = FemnistNetSmall() ##model\n",
    "    \n",
    "model_params_small = [param.data for param in model_small.parameters()]  # raw tensors instead of nn.Parameter\n",
    "\n",
    "\n",
    "X = th.tensor(np.zeros((10, 784)), dtype=th.float) ##784 sized 1D array. would be reshaped to 1, 28, 28\n",
    "y = nn.functional.one_hot(th.tensor(np.zeros(20, dtype=np.int64)), 62) ##62-length sized one hot vectors\n",
    "\n",
    "lr = th.tensor([0.0003]) ##0.0003 learning rate\n",
    "batch_size = th.tensor([float(10)]) ##20 is our batch size\n",
    "\n",
    "loss, acc, logits, target, *updated_params, _ = training_plan_small.build(X[0:10], y[0:10], batch_size, lr, model_params_small, trace_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutogradTensor>PlaceHolder[Id:23780437349]>tensor([4.16340876])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutogradTensor>PlaceHolder[Id:64711083574]>0.007499999832361937 AutogradTensor>PlaceHolder[Id:92881170128]>22.396770477294922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(AutogradTensor>PlaceHolder[Id:64711083574]>0.007499999832361937,\n",
       " AutogradTensor>PlaceHolder[Id:92881170128]>22.396770477294922)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "@sy.func2plan()\n",
    "def evaluate_model_plan(X, y, batch_size, model_params):\n",
    "    model = FemnistNet()\n",
    "    model.eval()\n",
    "    # Load model params into the model\n",
    "    set_model_params(model, model_params)\n",
    "    \n",
    "    # Test\n",
    "    logits, activations = model(X)\n",
    "    preds = th.argmax(logits, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    \n",
    "    acc = preds.eq(target).sum().float() / batch_size\n",
    "    loss = softmax_cross_entropy_with_logits(logits, y, batch_size)\n",
    "    \n",
    "    #mean_acc = th.mean(preds.eq(target).float())\n",
    "    print(acc, loss)\n",
    "    \n",
    "    return acc, loss\n",
    "\n",
    "# test_x = th.randn(3, INPUT_DIM)\n",
    "# test_y = nn.functional.one_hot(th.tensor([2,3,4]), CLASSES)\n",
    "\n",
    "# test_x = th.tensor(np.ones(shape=(5, 1, 28, 28)), dtype=th.float)\n",
    "# test_y = th.tensor(np.zeros(shape=(5, 62)))\n",
    "\n",
    "model = FemnistNet()\n",
    "# model.load_state_dict(th.load('./torch_model_weights'))\n",
    "# np_params = np.load('params.npy', allow_pickle=True)\n",
    "\n",
    "# model_params = [param.data.copy_(th.from_numpy(np_params[i])) for i, param in enumerate(model.parameters())]\n",
    "\n",
    "# load_model(model, modelPath)\n",
    "model_params = [param.data for param in model.parameters()]\n",
    "\n",
    "test_x = th.tensor(dataX_test, dtype=th.float)\n",
    "test_y = nn.functional.one_hot(th.tensor(dataY_test), 62) ##62-length sized one hot vectors\n",
    "\n",
    "\n",
    "# model_params = prune_model(model_params, create_mask(model_params))\n",
    "\n",
    "num = len(dataX_test)\n",
    "#evaluate_model_plan(test_x, test_y, th.tensor([3.0]), model_params)\n",
    "evaluate_model_plan.build(test_x[:num], test_y[:num], th.tensor(float(num)), model_params, trace_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FemnistNet()\n",
    "# np_params = np.load('params.npy', allow_pickle=True)\n",
    "\n",
    "# model_params = [param.data.copy_(th.from_numpy(np_params[i])) for i, param in enumerate(model.parameters())]\n",
    "\n",
    "# load_model(model, modelPath)\n",
    "modelParams = [param.data for param in model.parameters()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllData(path):\n",
    "    with open(path, 'r') as f:\n",
    "        user_data = json.load(f)\n",
    "        \n",
    "    return th.tensor(user_data['x'], dtype=th.float), nn.functional.one_hot(th.tensor(user_data['y']), 62)\n",
    "    \n",
    "class Client:\n",
    "    def __init__(self, train_data_path, test_data_path, training_plan_large, training_plan_small, eval_plan, is_slow = False):\n",
    "        self.dataX_train, self.dataY_train = getAllData(train_data_path)\n",
    "        self.dataX_test, self.dataY_test = getAllData(test_data_path)\n",
    "        \n",
    "        self.training_plan = training_plan_small if is_slow else training_plan_large\n",
    "        self.eval_plan = eval_plan\n",
    "        \n",
    "        self.is_slow = is_slow\n",
    "        \n",
    "    \n",
    "    def getNumSamples(self):\n",
    "        return self.getTrainSamples() + self.getTestSamples()\n",
    "    \n",
    "    def getTestSamples(self):\n",
    "        return len(self.dataY_test)\n",
    "    \n",
    "    def getTrainSamples(self):\n",
    "        return len(self.dataY_train)\n",
    "    \n",
    "        \n",
    "    def getBatch(self, batch_size):\n",
    "        batch_size_int = int(batch_size[0])\n",
    "        for i in range(0, len(self.dataY_train), batch_size_int):\n",
    "            end_index = i + batch_size_int if i + batch_size_int < len(self.dataY_train) else len(self.dataY_train)\n",
    "            yield (self.dataX_train[i:end_index], self.dataY_train[i:end_index])\n",
    "            \n",
    "    def getTestAccAndLoss(self, model_params):\n",
    "        return self.eval_plan(self.dataX_test, self.dataY_test, th.tensor([len(self.dataY_test)]), model_params)\n",
    "            \n",
    "    \n",
    "    def run_epochs(self, epochs, modelParams, batch_size, lr):\n",
    "        activations = []\n",
    "        if self.is_slow == False:\n",
    "            for epoch in range(epochs):\n",
    "                print(\"Epoch: \", epoch)\n",
    "                for batch in self.getBatch(batch_size):\n",
    "                    _, _, _, l2_activation, *updated_params = self.training_plan(batch[0], batch[1], batch_size, lr, modelParams.copy())\n",
    "                    modelParams = updated_params\n",
    "                    activations.append(l2_activation)\n",
    "        if len(activations) == 0:\n",
    "            return modelParams, None\n",
    "        else:\n",
    "            return modelParams, sum(activations)/len(activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_indexes = [0, 2, 4]\n",
    "bias_indexes = list(map(lambda i : i + 1, layer_indexes))\n",
    "\n",
    "def convert_filters_to_neuron_indices(filters, resulting_kernel_size):\n",
    "    neuron_indices = []\n",
    "    total_indices_in_one_filter = resulting_kernel_size * resulting_kernel_size\n",
    "    for filter_index in filters:\n",
    "        starting_index = filter_index * total_indices_in_one_filter\n",
    "        for i in range(total_indices_in_one_filter):\n",
    "            neuron_indices.append(i + starting_index)\n",
    "    return neuron_indices\n",
    "\n",
    "## Removing neurons & filters\n",
    "def remove_neurons_layer(weights, indices_to_remove):\n",
    "    return np.delete(weights, indices_to_remove, axis=0)\n",
    "\n",
    "def remove_neurons_next_layer(weights_next_layer, indices_to_remove):\n",
    "    return np.delete(weights_next_layer, indices_to_remove, axis=1)\n",
    "\n",
    "def remove_filters_layer(filters, indices_to_remove):\n",
    "    return np.delete(filters, indices_to_remove, axis=0)\n",
    "\n",
    "def remove_filters_next_layer(next_layer, indices_to_remove):\n",
    "    return np.delete(next_layer, indices_to_remove, axis=1)\n",
    "\n",
    "def remove_neurons_bias(bias, indices_to_remove):\n",
    "    return np.delete(bias, indices_to_remove)\n",
    "\n",
    "## Inserting neurons & filters\n",
    "def insert_neurons_layer(weights, indices):\n",
    "    new_weights = weights.copy() \n",
    "    for i in indices:\n",
    "        new_weights = np.insert(new_weights, i, 0, axis=0)\n",
    "    return new_weights\n",
    "\n",
    "def insert_neurons_next_layer(weights_next_layer, indices):\n",
    "    new_weights = weights_next_layer.copy() \n",
    "    for i in indices:\n",
    "        new_weights = np.insert(new_weights, i, 0, axis=1)\n",
    "    return new_weights\n",
    "\n",
    "def insert_filters_layer(filters, indices):\n",
    "    new_filters = filters.copy()\n",
    "    for i in indices:\n",
    "        new_filters = np.insert(new_filters, i, 0, axis=0)\n",
    "    return new_filters\n",
    "\n",
    "def insert_filters_next_layer(filters, indices):\n",
    "    new_filters = filters.copy()\n",
    "    for i in indices:\n",
    "        new_filters = np.insert(new_filters, i, 0, axis=1)\n",
    "    return new_filters\n",
    "\n",
    "def insert_neurons_bias(bias, indices_to_add):\n",
    "    prev_con = bias\n",
    "    indices = indices_to_add\n",
    "    for i in indices:\n",
    "        prev_con = np.insert(prev_con, i, 0, axis=0)\n",
    "    return prev_con\n",
    "\n",
    "\n",
    "def printModelDimensions(model):\n",
    "    for layer in model:\n",
    "        print(layer.shape)\n",
    "\n",
    "def convert_str_to_mask(str_mask):\n",
    "    return np.array([int(i) for i in str_mask.split(',')])\n",
    "\n",
    "\n",
    "def prune_model(modelParams, str_masks):\n",
    "    model_params = modelParams.copy()\n",
    "    str_masks = str_masks.split(';')\n",
    "\n",
    "    masks = list(map(lambda str_mask : convert_str_to_mask(str_mask), str_masks))\n",
    "\n",
    "\n",
    "    for i, layer_index in enumerate(layer_indexes):\n",
    "        mask = masks[i]\n",
    "        indices_to_remove = np.where(np.array(mask) == 0)[0]\n",
    "\n",
    "        if layer_index == 0:\n",
    "            model_params[0] = remove_filters_layer(model_params[0], indices_to_remove)\n",
    "            model_params[2] = remove_filters_next_layer(model_params[2], indices_to_remove)\n",
    "            \n",
    "        elif layer_index == 2:\n",
    "            numFilters = modelParams[2].shape[0]\n",
    "            numNeuronsShape = modelParams[4].shape[0]\n",
    "            \n",
    "            model_params[2] = remove_filters_layer(model_params[2], indices_to_remove)\n",
    "#             model_params[4] = model_params[4].t().reshape(7, 7, numFilters, -1).permute(3, 2, 0, 1)\n",
    "            neuron_indices_to_prune = convert_filters_to_neuron_indices(indices_to_remove, 7)\n",
    "            model_params[4] = remove_neurons_next_layer(model_params[4], neuron_indices_to_prune)\n",
    "#             model_params[4] = model_params[4].permute(2, 3, 1, 0).reshape(-1, numNeuronsShape).t()\n",
    "        \n",
    "        elif layer_index == 4:\n",
    "            model_params[4] = remove_neurons_layer(model_params[4], indices_to_remove)\n",
    "            \n",
    "            model_params[6] = remove_neurons_next_layer(model_params[6], indices_to_remove)\n",
    "            \n",
    "       \n",
    "        model_params[bias_indexes[i]] = remove_neurons_bias(model_params[bias_indexes[i]],\n",
    "                                                                 indices_to_remove)\n",
    "    \n",
    "    return model_params\n",
    "\n",
    "\n",
    "def convert_pruned_model_to_original(modelParams, str_masks):\n",
    "    model_params = modelParams.copy()\n",
    "    second_last_hidden_layer_params = model_params[-4]\n",
    "    second_last_hidden_layer_bias = model_params[-3]\n",
    "    output_layer = model_params[-2]\n",
    "\n",
    "\n",
    "    str_masks = str_masks.split(';')\n",
    "    masks = list(map(lambda str_mask : convert_str_to_mask(str_mask), str_masks))\n",
    "    \n",
    "    for i, layer_index in enumerate(layer_indexes):\n",
    "        mask = masks[i]\n",
    "        indices_to_remove = np.where(np.array(mask) == 0)[0]\n",
    "\n",
    "        if layer_index == 0:\n",
    "            model_params[0] = insert_filters_layer(model_params[0], indices_to_remove)\n",
    "            model_params[2] = insert_filters_next_layer(model_params[2], indices_to_remove)\n",
    "            \n",
    "        elif layer_index == 2:\n",
    "            numFilters = model_params[2].shape[0]\n",
    "            numNeuronsDense = model_params[4].shape[0]\n",
    "            \n",
    "            model_params[2] = insert_filters_layer(model_params[2], indices_to_remove)\n",
    "#             model_params[4] = model_params[4].t().reshape(7, 7, numFilters, -1).permute(3, 2, 0, 1)\n",
    "#             model_params[4] = insert_filters_next_layer(model_params[4], indices_to_remove).permute(2, 3, 1, 0).reshape(-1, numNeuronsDense).t()\n",
    "            neuron_indices_to_add = convert_filters_to_neuron_indices(indices_to_remove, 7)\n",
    "            model_params[4] = insert_neurons_next_layer(model_params[4], neuron_indices_to_add)\n",
    "        \n",
    "        elif layer_index == 4:\n",
    "            model_params[4] = insert_neurons_layer(model_params[4], indices_to_remove)\n",
    "            model_params[6] = insert_neurons_next_layer(model_params[6], indices_to_remove)\n",
    "        \n",
    "       \n",
    "        model_params[bias_indexes[i]] = insert_neurons_bias(model_params[bias_indexes[i]],\n",
    "                                                                 indices_to_remove)\n",
    "\n",
    "\n",
    "    return model_params\n",
    "\n",
    "\n",
    "def convert_pruned_activations_to_original(masks, activation_):\n",
    "    activation = activation_.copy()\n",
    "    mask = convert_str_to_mask(masks.split(';')[2])\n",
    "\n",
    "    indices_to_add = np.where( mask == 0)[0]\n",
    "\n",
    "    original_scaled_activation = insert_neurons_bias(activation, indices_to_add)\n",
    "\n",
    "    array = []\n",
    "    array.append(original_scaled_activation)\n",
    "\n",
    "    return original_scaled_activation\n",
    "\n",
    "\n",
    "def create_mask(params):\n",
    "    str_mask = \"\"\n",
    "\n",
    "    drop_rate = 0.5\n",
    "\n",
    "    for layer_index in layer_indexes:\n",
    "        if layer_index == 0 or layer_index == 2:\n",
    "            filter_shape = list(params[layer_index].shape)\n",
    "            number_of_filters = filter_shape[0]\n",
    "            mask = np.zeros(number_of_filters)\n",
    "            filters_to_keep = math.ceil(number_of_filters - (drop_rate * number_of_filters))\n",
    "            random_indices = np.random.choice(number_of_filters, size=filters_to_keep, replace=False)\n",
    "            values = [1] * len(random_indices)\n",
    "\n",
    "            np.put(mask, random_indices, values)\n",
    "\n",
    "            str_mask += ','.join([str(int(num)) for num in mask])\n",
    "            str_mask += \";\"\n",
    "            \n",
    "        else:\n",
    "            transposed_weights = th.transpose(params[layer_index], 0, 1)\n",
    "            neurons_shape = list(transposed_weights.shape)\n",
    "            number_of_neurons = neurons_shape[1]\n",
    "            mask = np.zeros(number_of_neurons)\n",
    "            neurons_to_keep = math.ceil(number_of_neurons - (drop_rate * number_of_neurons))\n",
    "            random_indices = np.random.choice(number_of_neurons, size=neurons_to_keep, replace=False)\n",
    "            values = [1] * len(random_indices)\n",
    "\n",
    "            np.put(mask, random_indices, values)\n",
    "\n",
    "            str_mask += ','.join([str(int(num)) for num in mask])\n",
    "            \n",
    "\n",
    "    return str_mask\n",
    "\n",
    "def update_mask(activations, prune_percentage):\n",
    "        \"\"\"\n",
    "            Based on bootstrap rounds update the mask for pruning the model\n",
    "        \"\"\"        \n",
    "        addition = th.stack(activations, dim=0).sum(dim=0)\n",
    "        avg_activations = th.div(addition, len(activations))\n",
    "\n",
    "\n",
    "        m = np.ones(len(avg_activations), dtype=int)\n",
    "        N = int(len(avg_activations) * prune_percentage)\n",
    "        argSortArray = avg_activations.argsort()\n",
    "\n",
    "        rind = argSortArray[:N].numpy()\n",
    "\n",
    "        m[rind] = 0\n",
    "\n",
    "        return ','.join([str(int(num)) for num in m])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'pysyft_simulation.csv'\n",
    "with open(fileName, 'w') as f:\n",
    "    f.write('Epoch,NumSamples,Type,Accuracy,Loss\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up clients & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logClientEval(epoch, client, acc, loss, file):\n",
    "    with open(file, 'a') as f:\n",
    "        strToWrite = str(epoch) + ',' + str(client.getNumSamples()) + ',' + ('L' if client.is_slow else 'H') + ',' + str(float(acc)) + ',' + str(float(loss)) + '\\n'\n",
    "        f.write(strToWrite)\n",
    "        \n",
    "def getAvgAccuracyAndLoss(epoch, modelParams, prunedModelParams, clients, file):\n",
    "    totalNumSamples = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss = 0\n",
    "    for client in clients:\n",
    "        modelParamsToServe = prunedModelParams if client.is_slow else modelParams\n",
    "        totalNumSamples += client.getNumSamples()\n",
    "        acc, loss = client.getTestAccAndLoss(modelParamsToServe)\n",
    "        print('Acc model with samples', client.getNumSamples(), acc)\n",
    "        avg_acc += (acc * client.getNumSamples())\n",
    "        avg_loss += (loss * client.getNumSamples())\n",
    "        \n",
    "\n",
    "        logClientEval(epoch, client, acc, loss, file)\n",
    "        \n",
    "    avg_acc /= totalNumSamples\n",
    "    avg_loss /= totalNumSamples\n",
    "    \n",
    "    with open(file, 'a') as f:\n",
    "        strToWrite = str(epoch) + ',' + str(totalNumSamples) + ',' + 'A' + ',' + str(float(avg_acc)) + ',' + str(float(avg_loss)) + '\\n'\n",
    "        f.write(strToWrite)\n",
    "    \n",
    "    return avg_acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where(filterArr, arr1, arr2, axis = 0):\n",
    "    if arr1.shape != arr2.shape:\n",
    "        print('Error: arr1 and arr2 must have equal shapes')\n",
    "        return\n",
    "    res = th.zeros(arr1.shape, dtype=arr1.dtype)\n",
    "    for i in range(filterArr.shape[0]):\n",
    "        if axis == 0:\n",
    "            res[i] = arr1[i] if filterArr[i] else arr2[i]\n",
    "        elif axis == 1:\n",
    "            res[:,i] = arr1[:,i] if filterArr[i] else arr2[:,i]\n",
    "    return res\n",
    "\n",
    "def aggregate_conv_dense_layer(weights_all, weights_high, layer_no, mask):\n",
    "    weights_all[layer_no] = where(mask, weights_all[layer_no], weights_high[layer_no])\n",
    "    weights_all[layer_no + 1] = where(mask, weights_all[layer_no + 1], weights_high[layer_no + 1])\n",
    "    weights_all[layer_no + 2] = where(mask, weights_all[layer_no + 2], weights_high[layer_no + 2], axis=1)\n",
    "    return weights_all\n",
    "\n",
    "def get_averaged_params(updates, weights, totalWeight):\n",
    "    aggregatedParams = [th.zeros(param.shape) for param in updates[0]]\n",
    "    for i, params in enumerate(updates):\n",
    "        for layer_index, param in enumerate(params):\n",
    "            aggregatedParams[layer_index] += ((param * weights[i])/totalWeight)\n",
    "            \n",
    "    return aggregatedParams\n",
    "    \n",
    "    \n",
    "def weighted_std(average, values, weights, totalWeight):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    std = [th.zeros(param.shape) for param in average]\n",
    "    for i, value in enumerate(values):\n",
    "        totalWeight += weights[i]\n",
    "        \n",
    "        for layer_no, layer in enumerate(value):\n",
    "            variance_layer = (layer - average[layer_no])**2\n",
    "            variance_layer = (variance_layer * weights[i])/totalWeight\n",
    "            std[layer_no] += th.sqrt(variance_layer)\n",
    "    \n",
    "    return std\n",
    "\n",
    "def get_aggregated_weights(masks, average_params, average_params_high):\n",
    "    for i, mask in enumerate(masks):\n",
    "        if i == 0 or i == 2:\n",
    "            averaged_soln = aggregate_conv_dense_layer(average_params, average_params_high, i * 2, mask)\n",
    "        elif i == 1:\n",
    "            numFilters = average_params[2].shape[0]\n",
    "            numNeuronsDense = average_params[4].shape[0]            \n",
    "\n",
    "            average_params[4] = average_params[4].reshape(-1, numFilters, 7, 7)\n",
    "            average_params_high[4] = average_params_high[4].reshape(-1, numFilters, 7, 7)\n",
    "            \n",
    "            averaged_soln = aggregate_conv_dense_layer(average_params, average_params_high, i * 2, mask)\n",
    "            \n",
    "            average_params[4] = average_params[4].reshape(numNeuronsDense, -1)\n",
    "            average_params_high[4] = average_params_high[4].reshape(numNeuronsDense, -1)\n",
    "            \n",
    "    return averaged_soln\n",
    "\n",
    "\n",
    "def get_aggregated_weights_clt(masks, average_params, average_params_high, std_params, std_params_high):\n",
    "    for i, mask in enumerate(masks):\n",
    "        if i == 0 or i == 2:\n",
    "            averaged_soln = aggregate_conv_dense_layer(average_params, average_params_high, i * 2, mask)\n",
    "            std_soln = aggregate_conv_dense_layer(std_params, std_params_high, i * 2, mask)\n",
    "        elif i == 1:\n",
    "            numFilters = average_params[2].shape[0]\n",
    "            numNeuronsDense = average_params[4].shape[0]            \n",
    "\n",
    "            average_params[4] = average_params[4].reshape(-1, numFilters, 7, 7)\n",
    "            average_params_high[4] = average_params_high[4].reshape(-1, numFilters, 7, 7)\n",
    "            \n",
    "            std_params[4] = std_params[4].reshape(-1, numFilters, 7, 7)\n",
    "            std_params_high[4] = std_params_high[4].reshape(-1, numFilters, 7, 7)\n",
    "            \n",
    "            averaged_soln = aggregate_conv_dense_layer(average_params, average_params_high, i * 2, mask)\n",
    "            std_soln = aggregate_conv_dense_layer(std_params, std_params_high, i * 2, mask)\n",
    "            \n",
    "            \n",
    "            average_params[4] = average_params[4].reshape(numNeuronsDense, -1)\n",
    "            average_params_high[4] = average_params_high[4].reshape(numNeuronsDense, -1)\n",
    "            \n",
    "            std_params[4] = std_params[4].reshape(numNeuronsDense, -1)\n",
    "            std_params_high[4] = std_params_high[4].reshape(numNeuronsDense, -1)\n",
    "            \n",
    "    return averaged_soln, std_soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = th.tensor(dataX_test, dtype=th.float)\n",
    "# y_test = nn.functional.one_hot(th.tensor(dataY_test), 62)\n",
    "# X = th.tensor(dataX, dtype=th.float)\n",
    "# y = nn.functional.one_hot(th.tensor(dataY), 62)\n",
    "\n",
    "trainFileFast = 'train_fast_random_20_2.json'\n",
    "testFileFast = 'test_fast_random_20_2.json'\n",
    "\n",
    "trainFileSlow = 'train_slow_random_20_1.json'\n",
    "testFileSlow = 'test_slow_random_20_1.json'\n",
    "\n",
    "trainfastClient = {}\n",
    "testfastClient = {}\n",
    "with open(trainFileFast, 'r') as f:\n",
    "    trainfastClient = json.load(f)\n",
    "with open(testFileFast, 'r') as f:\n",
    "    testfastClient = json.load(f)\n",
    "\n",
    "trainslowClient = {}\n",
    "testslowClient = {}\n",
    "with open(trainFileSlow, 'r') as f:\n",
    "    trainslowClient = json.load(f)\n",
    "with open(testFileSlow, 'r') as f:\n",
    "    testslowClient = json.load(f)\n",
    "    \n",
    "fast_client = Client(trainFileFast,\n",
    "                 testFileFast,\n",
    "                 training_plan.torchscript, \n",
    "                 training_plan_small.torchscript, \n",
    "                 evaluate_model_plan.torchscript)\n",
    "\n",
    "slow_client = Client(trainFileSlow,\n",
    "                 testFileSlow,\n",
    "                 training_plan.torchscript, \n",
    "                 training_plan_small.torchscript, \n",
    "                 evaluate_model_plan.torchscript,\n",
    "                True)\n",
    "\n",
    "clients = [fast_client, slow_client]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "epochs = 10\n",
    "rounds = 100\n",
    "batch_size = th.tensor([float(10)])\n",
    "lr = th.tensor([0.0003])\n",
    "needToPrune = False\n",
    "\n",
    "if needToPrune:\n",
    "    model = FemnistNet()\n",
    "else:\n",
    "    model = FemnistNet()\n",
    "     \n",
    "# load_model(model, modelPathForPruning)\n",
    "# load_model(model, 'kamming_femnist_model.npy')\n",
    "modelParams = [param.data for param in model.parameters()]\n",
    "bootstrap_rounds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_masks = create_mask(modelParams.copy())\n",
    "str_masks='0,1,1,0,1,1,0,1,0,0,0,1,0,0,0,1,1,0,1,1,0,0,1,1,0,0,0,0,1,1,1,1;1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0,0,0,1,0,1,0,1,0,0,0,0,1,1,1,0,0,0,0,0,1,1,0,0,0,0,1,1,0,1,1,0,0,0,0;0,0,1,0,0,1,1,1,0,0,1,1,0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,1,0,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,0,0,1,0,0,1,1,0,1,1,1,0,1,0,1,0,0,0,1,1,1,1,1,0,1,0,0,1,0,0,0,0,0,1,0,1,0,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,0,1,0,0,0,1,1,1,0,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,0,0,0,1,1,0,1,1,1,0,0,1,0,1,0,0,0,0,0,1,1,0,1,1,1,0,0,0,0,0,1,1,1,0,1,1,0,1,1,1,0,0,0,1,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,1,1,0,0,0,0,1,0,0,0,1,0,1,0,0,0,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,0,0,0,0,0,1,1,1,0,1,1,1,0,0,0,1,0,1,1,0,1,0,1,1,1,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,1,0,1,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,0,1,1,1,1,0,0,0,0,1,1,0,0,1,1,0,0,0,0,1,1,1,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,1,0,0,0,1,0,1,1,1,0,0,1,1,0,1,0,0,1,0,1,0,1,0,1,1,1,0,1,1,0,0,0,0,0,1,0,0,0,1,1,1,0,1,1,0,1,0,1,0,1,1,1,0,1,0,1,1,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,0,0,0,0,1,1,1,1,0,1,0,0,1,0,0,1,0,1,0,0,1,0,0,1,1,1,0,1,0,1,0,0,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,1,1,1,1,0,0,0,1,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,0,0,0,0,0,0,1,0,1,1,0,1,0,1,0,1,0,0,0,1,0,1,1,1,0,1,1,0,1,1,0,1,0,0,1,1,0,0,1,1,1,0,0,0,1,0,0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,1,0,1,0,0,1,1,1,0,0,0,1,1,1,0,0,1,0,0,0,0,0,1,0,1,1,1,1,0,0,1,0,1,0,0,1,0,0,1,0,1,0,0,1,1,1,0,0,1,0,1,0,1,1,1,0,0,1,1,1,0,0,0,1,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,1,0,0,1,1,0,0,0,0,0,1,0,0,1,1,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,1,1,0,0,0,1,1,0,1,0,1,0,0,0,1,0,0,0,0,1,1,0,0,1,0,1,0,0,0,0,0,1,0,1,1,0,1,1,1,1,0,1,0,1,0,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,1,0,1,1,1,1,1,1,1,1,0,0,0,0,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,1,0,1,0,0,0,1,1,0,1,1,0,1,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,1,1,1,0,1,1,1,0,1,0,0,1,0,1,1,0,0,0,1,1,1,1,0,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,1,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,1,0,0,1,0,0,1,0,0,1,0,1,1,0,1,0,0,1,0,1,1,1,1,1,0,0,1,0,1,0,0,1,1,1,0,0,0,0,1,1,0,1,1,0,0,0,1,0,1,0,1,0,1,1,1,0,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,1,0,1,1,1,0,1,0,0,0,1,1,0,0,1,0,0,1,0,1,0,0,1,1,1,1,0,1,1,0,0,0,1,0,0,1,0,1,0,1,1,1,1,1,1,0,1,0,1,1,1,0,0,0,1,1,1,0,1,1,1,0,0,1,0,0,1,0,0,1,1,1,1,1,0,0,1,1,1,0,1,1,0,0,0,0,1,1,1,0,1,0,1,1,0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,0,1,0,1,0,0,0,1,1,0,1,1,0,0,0,1,0,1,1,0,1,1,0,0,0,1,1,0,0,1,1,0,0,0,0,1,1,0,1,0,0,0,0,0,1,0,1,1,1,0,0,0,1,0,1,1,0,0,0,0,1,1,0,1,0,0,1,1,0,0,1,1,0,1,0,1,1,1,1,0,1,0,0,0,1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,0,1,0,1,0,1,0,0,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,1,0,0,1,1,1,0,0,1,1,0,1,1,1,1,0,0,0,1,1,0,0,0,0,0,1,1,0,1,0,0,1,0,0,0,0,1,1,1,1,0,0,1,1,0,0,0,1,0,1,1,1,0,0,0,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,1,0,0,1,1,0,0,1,1,0,0,0,1,1,0,1,1,1,1,0,0,1,1,0,1,0,1,1,1,0,0,1,0,1,1,0,0,0,1,1,1,0,1,1,1,0,0,0,1,0,1,0,0,0,1,1,1,0,0,1,0,1,1,0,0,0,1,0,0,0,1,1,1,1,0,1,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,1,1,0,0,1,0,1,0,0,0,0,0,1,1,1,1,0,1,1,0,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,1,1,1,0,0,0,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,0,0,0,0,0,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,0,0,1,1,0,0,0,0,1,0,1,0,1,1,0,1,1,0,0,1,0,1,0,1,0,1,1,1,0,0,1,1,1,1,0,1,0,0,0,0,0,0,1,0,1,1,1,1,1,0,0,1,0,1,1,0,1,0,0,0,1,0,0,1,1,0,1,1,1,1,1,0,0,0,0,0,1,1,0,1,1,0,0,1,1,0,1,0,1,1,1,0,1,1,0,1,0,1,0,0,1,1,1,0,1,0,1,1,0,1,1,0,0,0,0,1,1,1,0,1,1,0,0,1,0,1,1,0,1,1,0,1,0,0,0,0,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,0,1,0,0,1,1,0,1,0,1,0,0,0,1,1,0,1,1,1,0,1,0,1,1,0,0,1,0,0,0,1,1,0,0,1,1,1,1,0,1,0,0,1,1,0,0,0,1,0,0,0,1,1,1,1,1,1,0,1,0,0,0,1,1,1,1,0,1,0,1,0,0,1,1,1,0,0,0,0,0,0,1,1,0,0,1,1,1,0,0,1,1,1,0,1,0,1,0,0,1,0,1,0,0,0,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1,0,1,0,1,1,0,0,1,1,1,1,1,1,0,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,1,0,0,0,0,1,0,1,1,0,1,0,0,0,1,0,0,0,0,0,1,0,1,1,1,0,1,0,1,1,1,0,0,0,1,0,0,0,1,0,1,1,1,0,1,1,0,1,1,0,0,1,0,0,0,1,1,0,1,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,1,1,1,0,0,1,0,1,0,0,1,1,0,1,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1,1,0,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,1,0,0,1,1,0,0,1,0,1,0,1,1,0,1,1,0,1,0,1,1,0,1,0,0,1,1,1,1,0,1,1,1,0,1,1,0,0,1,0,0,1,0,0,1,0,1,0,0,0,0,1,1,1,1,1,0,0,1,0,0,0,0,1,1,1,0,0,1,0,0,1,0,1,0,1,1,1,1,1,0,1,0,0,0,0,0,0,0,0,1,1,1,0,1,1,0,0,0,1,0,0,1,0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_plan_torchscript = training_plan.torchscript\n",
    "training_plan_small_torchscript = training_plan_small.torchscript\n",
    "\n",
    "evaluate_model_plan_torchscript = evaluate_model_plan.torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Currently, mask is not being updated and averaging isn't selective (same averaging for all clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round No:  0\n",
      "Acc model with samples 250 tensor([0.06000000])\n",
      "Acc model with samples 250 tensor([0.14000000])\n",
      "Epoch 0 Acc: tensor([0.10000000]) Loss: tensor([11.26898575], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  1\n",
      "Acc model with samples 250 tensor([0.04000000])\n",
      "Acc model with samples 250 tensor([0.12000000])\n",
      "Epoch 1 Acc: tensor([0.08000000]) Loss: tensor([6.16666508], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  2\n",
      "Acc model with samples 250 tensor([0.50000000])\n",
      "Acc model with samples 250 tensor([0.10000000])\n",
      "Epoch 2 Acc: tensor([0.30000001]) Loss: tensor([3.99033332], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  3\n",
      "Acc model with samples 250 tensor([0.56000000])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 3 Acc: tensor([0.28999999]) Loss: tensor([3.73222065], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  4\n",
      "Acc model with samples 250 tensor([0.56000000])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 4 Acc: tensor([0.28999999]) Loss: tensor([3.66830397], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  5\n",
      "Acc model with samples 250 tensor([0.56000000])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 5 Acc: tensor([0.28999999]) Loss: tensor([3.66368341], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  6\n",
      "Acc model with samples 250 tensor([0.56000000])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 6 Acc: tensor([0.28000000]) Loss: tensor([3.66970062], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  7\n",
      "Acc model with samples 250 tensor([0.56000000])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 7 Acc: tensor([0.28000000]) Loss: tensor([3.67865539], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  8\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 8 Acc: tensor([0.28999999]) Loss: tensor([3.68821192], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  9\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 9 Acc: tensor([0.28999999]) Loss: tensor([3.69764161], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  10\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 10 Acc: tensor([0.28999999]) Loss: tensor([3.70646429], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  11\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 11 Acc: tensor([0.28999999]) Loss: tensor([3.71472931], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  12\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 12 Acc: tensor([0.28999999]) Loss: tensor([3.72241998], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  13\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 13 Acc: tensor([0.28999999]) Loss: tensor([3.72979546], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  14\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.])\n",
      "Epoch 14 Acc: tensor([0.28999999]) Loss: tensor([3.73674273], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  15\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 15 Acc: tensor([0.30000001]) Loss: tensor([3.74310398], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  16\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 16 Acc: tensor([0.30000001]) Loss: tensor([3.74886823], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  17\n",
      "Acc model with samples 250 tensor([0.57999998])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 17 Acc: tensor([0.30000001]) Loss: tensor([3.75425982], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  18\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 18 Acc: tensor([0.31000000]) Loss: tensor([3.75924778], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  19\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 19 Acc: tensor([0.31000000]) Loss: tensor([3.76403475], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  20\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 20 Acc: tensor([0.31000000]) Loss: tensor([3.76862288], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  21\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 21 Acc: tensor([0.31000000]) Loss: tensor([3.77308512], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  22\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 22 Acc: tensor([0.31000000]) Loss: tensor([3.77739263], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  23\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 23 Acc: tensor([0.31000000]) Loss: tensor([3.78158665], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  24\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 24 Acc: tensor([0.31000000]) Loss: tensor([3.78574419], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  25\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 25 Acc: tensor([0.31000000]) Loss: tensor([3.78984427], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  26\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 26 Acc: tensor([0.31000000]) Loss: tensor([3.79383111], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  27\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 27 Acc: tensor([0.31000000]) Loss: tensor([3.79761672], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  28\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 28 Acc: tensor([0.31000000]) Loss: tensor([3.80127740], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  29\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 29 Acc: tensor([0.31000000]) Loss: tensor([3.80477691], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  30\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 30 Acc: tensor([0.31000000]) Loss: tensor([3.80814838], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  31\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 31 Acc: tensor([0.31000000]) Loss: tensor([3.81141591], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Round No:  32\n",
      "Acc model with samples 250 tensor([0.60000002])\n",
      "Acc model with samples 250 tensor([0.02000000])\n",
      "Epoch 32 Acc: tensor([0.31000000]) Loss: tensor([3.81461573], grad_fn=<DivBackward0>)\n",
      "\n",
      "Epoch:  0\n"
     ]
    }
   ],
   "source": [
    "activations = []\n",
    "torch_losses = []\n",
    "torch_accs = []\n",
    "masks = list(map(lambda str_mask : convert_str_to_mask(str_mask), str_masks.split(';')))\n",
    "\n",
    "for e in range(rounds):\n",
    "    print(\"Round No: \", e)\n",
    "    evaluate_model_plan_copy = evaluate_model_plan.copy()\n",
    "    \n",
    "#     if e % bootstrap_rounds == 0 and e != 0:\n",
    "#         print('updating mask')\n",
    "#         old_masks = str_masks.split(\";\")\n",
    "#         old_masks[2] = update_mask(activations, 0.5)\n",
    "#         str_masks = ';'.join(old_masks)\n",
    "#         activations = []\n",
    "\n",
    "\n",
    "\n",
    "    prunedModelParams = prune_model(modelParams.copy(), str_masks)\n",
    "    \n",
    "    allNumSamples = []\n",
    "    allHighNumSamples = []\n",
    "    \n",
    "    allModelParams = []\n",
    "    highModelParams = []\n",
    "    \n",
    "    totalNumSamples = 0\n",
    "    totalHighNumSamples = 0\n",
    "    \n",
    "    testSamples = 0\n",
    "    \n",
    "    weighted_epoch_acc, weighted_epoch_loss = getAvgAccuracyAndLoss(e, modelParams, prunedModelParams, clients, fileName)\n",
    "    print('Epoch', e, 'Acc:', weighted_epoch_acc, 'Loss:', weighted_epoch_loss)\n",
    "    print()    \n",
    "    \n",
    "    for client in clients:\n",
    "        modelParamsToServe = prunedModelParams if client.is_slow and needToPrune else modelParams\n",
    "        allNumSamples.append(client.getNumSamples())\n",
    "        totalNumSamples += client.getNumSamples()\n",
    "        \n",
    "        if not client.is_slow:\n",
    "            allHighNumSamples.append(client.getNumSamples())\n",
    "            totalHighNumSamples += client.getNumSamples()\n",
    "        \n",
    "                \n",
    "        updatedModelParams, l2_activation = client.run_epochs(epochs, modelParamsToServe.copy(), batch_size, lr)\n",
    "                    \n",
    "        if client.is_slow and needToPrune:\n",
    "            updatedModelParams = convert_pruned_model_to_original(updatedModelParams, str_masks)\n",
    "            mask = masks[2]\n",
    "            indices_to_add = np.where( mask == 0)\n",
    "            l2_activation = convert_pruned_activations_to_original(str_masks, l2_activation)\n",
    "        \n",
    "    \n",
    "#         updatedModelParams = [param for param in updatedModelParams]\n",
    "        allModelParams.append(updatedModelParams)\n",
    "        \n",
    "        if not client.is_slow:\n",
    "            highModelParams.append(updatedModelParams)\n",
    "            \n",
    "    \n",
    "    averaged_params = get_averaged_params(allModelParams, allNumSamples, totalNumSamples)\n",
    "#     averaged_params_high = get_averaged_params(allModelParams, allNumSamples, totalNumSamples)\n",
    "    \n",
    "#     std_params = weighted_std(averaged_params, allModelParams, allNumSamples, totalNumSamples)\n",
    "#     std_params_high = weighted_std(averaged_params_high, highModelParams, allHighNumSamples, totalHighNumSamples)\n",
    "    \n",
    "#     aggregatedParams, aggregatedStd = get_aggregated_weights_clt(masks, averaged_params, averaged_params_high, std_params, std_params_high)        \n",
    "#     new_params = [th.normal(mean = aggregatedParams[i], std = aggregatedStd[i]) for i in range(len(aggregatedParams))]\n",
    "        \n",
    "#     modelParams = new_params\n",
    "    modelParams = averaged_params\n",
    "\n",
    "    torch_losses.append(weighted_epoch_loss)\n",
    "    torch_accs.append(weighted_epoch_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(activations)def getCsvRow(vals):\n",
    "    row = list(map(lambda val : str(val), vals))\n",
    "    row = ','.join(row)\n",
    "    row += '\\n'\n",
    "    return row\n",
    "\n",
    "import os\n",
    "\n",
    "feddrop_50_percent_2_clients = pd.read_csv('50_percent_2_clients_feddrop.csv')\n",
    "feddrop_50_percent_2_clients_clt = pd.read_csv('50_percent_2_clients_feddrop_clt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "feddrop_slow_client = feddrop_50_percent_2_clients[feddrop_50_percent_2_clients['num_samples'] == 650]\n",
    "feddrop_slow_client = feddrop_slow_client[feddrop_slow_client['set'] == 'test']\n",
    "\n",
    "feddrop_fast_client = feddrop_50_percent_2_clients[feddrop_50_percent_2_clients['num_samples'] == 1750]\n",
    "feddrop_fast_client = feddrop_fast_client[feddrop_fast_client['set'] == 'test']\n",
    "\n",
    "avg_acc = (np.array(feddrop_slow_client['accuracy'] * 650) + np.array(feddrop_fast_client ['accuracy'] * 1750))/2400\n",
    "avg_loss = (np.array(feddrop_slow_client['loss'] * 650) + np.array(feddrop_fast_client ['loss'] * 1750))/2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "feddrop_clt_slow_client = feddrop_50_percent_2_clients_clt[feddrop_50_percent_2_clients_clt['num_samples'] == 650]\n",
    "feddrop_clt_slow_client = feddrop_clt_slow_client[feddrop_clt_slow_client['set'] == 'test']\n",
    "\n",
    "feddrop_clt_fast_client = feddrop_50_percent_2_clients_clt[feddrop_50_percent_2_clients_clt['num_samples'] == 1750]\n",
    "feddrop_clt_fast_client = feddrop_clt_fast_client[feddrop_clt_fast_client['set'] == 'test']\n",
    "\n",
    "avg_acc_clt = (np.array(feddrop_clt_slow_client['accuracy'] * 650) + np.array(feddrop_clt_fast_client ['accuracy'] * 1750))/2400\n",
    "avg_loss_clt = (np.array(feddrop_clt_slow_client['loss'] * 650) + np.array(feddrop_clt_fast_client ['loss'] * 1750))/2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbed_500_fast = pd.read_csv('testbed_500_fast.csv')\n",
    "pytorch_500_fast = pd.read_csv('pytorch_500_fast.csv')\n",
    "tf_500_fast = pd.read_csv('tf_500_fast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysyft_50_percent_2_clients = pd.read_csv(fileName)\n",
    "\n",
    "pysyft_slow_client = pysyft_50_percent_2_clients[pysyft_50_percent_2_clients['Type'] == 'L']\n",
    "pysyft_fast_client = pysyft_50_percent_2_clients[pysyft_50_percent_2_clients['Type'] == 'H']\n",
    "pysyft_avg = pysyft_50_percent_2_clients[pysyft_50_percent_2_clients['Type'] == 'A']\n",
    "\n",
    "\n",
    "pysyft_avg_acc = np.array(pysyft_avg['Accuracy'])\n",
    "pysyft_avg_loss = np.array(pysyft_avg['Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pl\n",
    "# plt.title('Average Accuracy: PySyft vs Tensorflow - 50 percent pruning - 1 fast, 1 slow')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Round/Epoch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(kammingFemnist['Accuracy'])\n",
    "\n",
    "# plt.plot(list(testbed_500_fast['accuracy'])[0:len(torch_losses)])\n",
    "# plt.plot(list(pytorch_500_fast['acc'])[0:len(torch_losses)])\n",
    "\n",
    "# plt.plot(list(tf_500_fast['acc'])[0:len(torch_losses)])\n",
    "plt.plot(pysyft_avg_acc)\n",
    "plt.plot(avg_acc_clt[:len(torch_accs)])\n",
    "\n",
    "# plt.plot(hist2.history['accuracy'])\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(list(femnist_stat_train['loss'])[0:len(torch_losses)])\n",
    "\n",
    "plt.title('Average Accuracy: PySyft CLT vs Tensorflow CLT - 50 percent pruning - 1 fast, 1 slow')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Round/Epoch')\n",
    "\n",
    "plt.legend(['PySyft', 'FedDrop (Tensorflow)'], loc='lower right')\n",
    "\n",
    "plt.savefig('pysyft_vs_tf_clt_acc_2_clients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(kammingFemnist['Accuracy'])\n",
    "\n",
    "# plt.plot(list(testbed_500_fast['accuracy'])[0:len(torch_losses)])\n",
    "# plt.plot(list(pytorch_500_fast['acc'])[0:len(torch_losses)])\n",
    "\n",
    "# plt.plot(list(tf_500_fast['acc'])[0:len(torch_losses)])\n",
    "plt.plot(pysyft_avg_acc)\n",
    "plt.plot(list(pysyft_fast_client['Accuracy']))\n",
    "plt.plot(list(pysyft_slow_client['Accuracy']))\n",
    "\n",
    "\n",
    "# plt.plot(hist2.history['accuracy'])\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(list(femnist_stat_train['loss'])[0:len(torch_losses)])\n",
    "\n",
    "plt.title('Accuracy: PySyft CLT with 2 clients (1 fast & 1 Slow) - 50% pruning')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Round/Epoch')\n",
    "\n",
    "plt.legend(['H + L', 'H', 'L'], loc='lower right')\n",
    "\n",
    "plt.savefig('pysyft_clt_2_clients_50_percent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(kammingFemnist['Accuracy'])\n",
    "\n",
    "# plt.plot(list(testbed_500_fast['accuracy'])[0:len(torch_losses)])\n",
    "# plt.plot(list(pytorch_500_fast['acc'])[0:len(torch_losses)])\n",
    "\n",
    "# plt.plot(list(tf_500_fast['acc'])[0:len(torch_losses)])\n",
    "plt.plot(avg_acc_clt)\n",
    "plt.plot(list(feddrop_clt_fast_client['accuracy']))\n",
    "plt.plot(list(feddrop_clt_slow_client['accuracy']))\n",
    "\n",
    "\n",
    "# plt.plot(hist2.history['accuracy'])\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(list(femnist_stat_train['loss'])[0:len(torch_losses)])\n",
    "\n",
    "plt.title('Accuracy: Tesorflow/FedDrop CLT with 2 clients (1 fast & 1 Slow) - 50 %pruning')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Round/Epoch')\n",
    "\n",
    "plt.legend(['H + L', 'H', 'L'], loc='lower right')\n",
    "\n",
    "plt.savefig('feddrop_clt_2_clients_50_percent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e9da01c58bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plt.plot(kammingFemnist['Accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestbed_500_fast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytorch_500_fast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plt.plot(kammingFemnist['Accuracy'])\n",
    "\n",
    "plt.plot(list(testbed_500_fast['loss'])[0:len(torch_losses)])\n",
    "plt.plot(list(pytorch_500_fast['loss'])[0:len(torch_losses)])\n",
    "\n",
    "plt.plot(list(list(map(lambda x : float(x), torch_losses))))\n",
    "# plt.plot(hist2.history['accuracy'])\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(list(femnist_stat_train['loss'])[0:len(torch_losses)])\n",
    "\n",
    "plt.title('Loss: PySyft vs PyTorch vs Testbed')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Round/Epoch')\n",
    "\n",
    "plt.legend(['Testbed', 'PyTorch', 'PySyft'], loc='lower right')\n",
    "\n",
    "plt.savefig('pysyft_testbed_pytorch_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = [param.detach() for param in FemnistNet().parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunedModel = prune_model(modelParams, str_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 5, 5])\n",
      "torch.Size([64])\n",
      "torch.Size([2048, 3136])\n",
      "torch.Size([2048])\n",
      "torch.Size([62, 2048])\n",
      "torch.Size([62])\n"
     ]
    }
   ],
   "source": [
    "for i, param in enumerate(modelParams):\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalModel = convert_pruned_model_to_original(prunedModel.copy(), str_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.04844368,  0.05829063,  0.06482986, -0.00037938,  0.03582773],\n",
       "           [-0.04473288,  0.03160680, -0.07192211,  0.04808041, -0.01475582],\n",
       "           [-0.04021096, -0.01238550,  0.07502086,  0.02516533,  0.04875748],\n",
       "           [-0.08481959,  0.03014215,  0.06911427, -0.02099419,  0.00149267],\n",
       "           [-0.05584396, -0.05114162, -0.08379941, -0.07522546,  0.00803423]]],\n",
       " \n",
       " \n",
       "         [[[-0.01890411,  0.02716055,  0.08087714,  0.06115712,  0.08462429],\n",
       "           [ 0.03856171,  0.06971835,  0.08150141,  0.02088659, -0.04605213],\n",
       "           [ 0.06806611,  0.05744293,  0.08113788, -0.04898061, -0.02105553],\n",
       "           [ 0.01540595,  0.04489534,  0.03256555,  0.03316144, -0.06504034],\n",
       "           [ 0.02001496,  0.07980520, -0.06566805, -0.01010335, -0.04405257]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.07423592, -0.05125437, -0.06619664, -0.01274159,  0.01021489],\n",
       "           [-0.06276517,  0.08011705,  0.03748520, -0.06229507,  0.06602916],\n",
       "           [ 0.00473219, -0.05548393, -0.02807406, -0.01014290, -0.07985185],\n",
       "           [ 0.07959700, -0.02171353, -0.01953296,  0.00587820,  0.03903677],\n",
       "           [ 0.06884764, -0.05712325,  0.07156454, -0.07628807,  0.05639188]]],\n",
       " \n",
       " \n",
       "         [[[-0.06754114,  0.03935809, -0.04799566, -0.01528876,  0.00287569],\n",
       "           [-0.01738717, -0.00191532,  0.01011837, -0.05364234,  0.06689110],\n",
       "           [-0.08034866, -0.06441347,  0.04701412,  0.05509371, -0.06936031],\n",
       "           [ 0.05497888, -0.06121850,  0.01623888,  0.03239373,  0.02523666],\n",
       "           [-0.03764357,  0.00432211, -0.01560474,  0.06259587,  0.00776463]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00577649, -0.02641816,  0.02020431,  0.05597195, -0.01189048],\n",
       "           [-0.03963581,  0.01025723, -0.00546320, -0.04932800,  0.04118632],\n",
       "           [-0.05362326,  0.02406134, -0.04692725, -0.04587569, -0.04224141],\n",
       "           [-0.06880878, -0.05275637,  0.00910056,  0.04267028, -0.07408337],\n",
       "           [ 0.03213961,  0.03789078,  0.08015665,  0.01903722,  0.01450763]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[-0.08465520,  0.07454690,  0.06946269, -0.03360638,  0.06622022],\n",
       "           [ 0.03983735, -0.05692500, -0.02909494, -0.04371936,  0.06108961],\n",
       "           [-0.03009411,  0.07667984,  0.01887979, -0.02512785, -0.01475886],\n",
       "           [ 0.03284105,  0.07301390, -0.07120478, -0.04100738, -0.00721172],\n",
       "           [ 0.03112799, -0.00711057,  0.04948820, -0.00047868,  0.04193681]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[-0.05388076,  0.00589657, -0.05041185,  0.01192077, -0.03288574],\n",
       "           [ 0.01442005, -0.03042192, -0.05022196,  0.07557860, -0.02856341],\n",
       "           [ 0.05612265,  0.02085792, -0.05537435, -0.02428157,  0.03604636],\n",
       "           [ 0.02536012,  0.03111135, -0.06142353,  0.04804616, -0.04240496],\n",
       "           [-0.03434419,  0.06945524, -0.03232203,  0.02651215,  0.02767710]]],\n",
       " \n",
       " \n",
       "         [[[ 0.01109114, -0.02808629, -0.07547945, -0.06319402,  0.03603935],\n",
       "           [-0.06041022, -0.03148511,  0.06864426,  0.02289152, -0.03988709],\n",
       "           [-0.02269678, -0.06778874,  0.02224734,  0.02577373, -0.01994468],\n",
       "           [ 0.04987787, -0.05473779,  0.06565763, -0.03377686,  0.06155589],\n",
       "           [ 0.03145383,  0.00703356,  0.01378154, -0.01791712, -0.07073265]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.08013551,  0.06117599,  0.04650989, -0.00887921, -0.06953639],\n",
       "           [-0.03834939, -0.07710607,  0.00814315, -0.03941404, -0.07592808],\n",
       "           [ 0.00578756, -0.07332635,  0.02186833,  0.05916052, -0.01729552],\n",
       "           [ 0.06298804,  0.00852334,  0.07490267, -0.02819524,  0.07120961],\n",
       "           [ 0.01009007, -0.03477889,  0.03629442, -0.01319641,  0.01109047]]],\n",
       " \n",
       " \n",
       "         [[[ 0.03615171, -0.08280973,  0.01586232, -0.03505780, -0.06819306],\n",
       "           [-0.06286940,  0.02794629, -0.06170376, -0.02201644,  0.02683395],\n",
       "           [-0.07539003,  0.06652088, -0.05006012,  0.03750464,  0.00707820],\n",
       "           [-0.04170536, -0.03093399, -0.04081349,  0.03845838, -0.02065197],\n",
       "           [ 0.08289707, -0.06552950, -0.05898034,  0.02122417, -0.03152861]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.06366250, -0.07887692, -0.01404854,  0.02571982, -0.05706216],\n",
       "           [ 0.03476699, -0.02158213,  0.03485905, -0.06350388,  0.07559642],\n",
       "           [ 0.00384090, -0.03791607, -0.03120488, -0.06149527,  0.05171648],\n",
       "           [-0.06841124,  0.07287371, -0.03279089, -0.02676497, -0.03308035],\n",
       "           [-0.01704048,  0.07184540,  0.06542279, -0.00922586,  0.02842392]]],\n",
       " \n",
       " \n",
       "         [[[-0.00962681,  0.01798947, -0.05385663, -0.00919165,  0.06446391],\n",
       "           [ 0.01132596,  0.07432026, -0.02405516,  0.07763150, -0.06637014],\n",
       "           [-0.03515239,  0.04629381, -0.05499325, -0.02602571, -0.04011011],\n",
       "           [-0.01058330,  0.01810910, -0.00145596,  0.08193238,  0.07656749],\n",
       "           [-0.00410071,  0.01400820, -0.01848925, -0.04705951,  0.03935453]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.03613886,  0.07836822,  0.05346386, -0.03086790,  0.00569790],\n",
       "           [ 0.03021947, -0.04793297,  0.03359801,  0.07600518, -0.05837722],\n",
       "           [-0.04578085, -0.02408153,  0.08340459,  0.05142863,  0.07707687],\n",
       "           [ 0.06645714,  0.03505095,  0.07900323, -0.05538959,  0.04938056],\n",
       "           [ 0.04285678,  0.04296936,  0.00720181, -0.02149013, -0.08491769]]],\n",
       " \n",
       " \n",
       "         [[[-0.01323974, -0.06717028, -0.07947886,  0.02627150,  0.05384852],\n",
       "           [-0.04572500, -0.02581372,  0.04519613,  0.08186376, -0.00093238],\n",
       "           [ 0.03411610, -0.03626975, -0.02962031, -0.06703740, -0.07878109],\n",
       "           [ 0.01233320, -0.06445105, -0.01093302,  0.05362776, -0.08102603],\n",
       "           [ 0.05634393,  0.07217932, -0.06816791, -0.01164497, -0.06031089]]],\n",
       " \n",
       " \n",
       "         [[[-0.05765337, -0.02885115,  0.06977578,  0.01063229,  0.06793243],\n",
       "           [ 0.05518994,  0.05985075, -0.03168412, -0.06005383,  0.04295310],\n",
       "           [ 0.03326801,  0.02362899, -0.08027796, -0.05976363,  0.02829885],\n",
       "           [ 0.04408552,  0.00417942,  0.02964408, -0.02367242,  0.05470517],\n",
       "           [-0.01507925, -0.04117820,  0.02082251, -0.03099097,  0.07561387]]],\n",
       " \n",
       " \n",
       "         [[[-0.00229688, -0.07165018, -0.02414665, -0.06535555, -0.02020578],\n",
       "           [-0.01517975, -0.07440664,  0.02669106, -0.04399443, -0.03714638],\n",
       "           [-0.06686238,  0.04749191, -0.08503105, -0.07942209,  0.05112445],\n",
       "           [ 0.01947643, -0.05260486, -0.01308265,  0.07420972,  0.02910350],\n",
       "           [-0.07539406,  0.05593477,  0.02612317, -0.07259049,  0.06798829]]]]),\n",
       " tensor([ 0.00000000,  0.11684166,  0.11655416,  0.00000000,  0.17319210,\n",
       "          0.09416012,  0.00000000, -0.15880871,  0.00000000,  0.00000000,\n",
       "          0.00000000,  0.09444441,  0.00000000,  0.00000000,  0.00000000,\n",
       "          0.14867331, -0.17493442,  0.00000000,  0.00552233, -0.09209271,\n",
       "          0.00000000,  0.00000000, -0.13923287,  0.09733601,  0.00000000,\n",
       "          0.00000000,  0.00000000,  0.00000000, -0.13362989, -0.07768793,\n",
       "          0.10278414,  0.11368717]),\n",
       " tensor([[[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[-0.04033152, -0.03953357, -0.02986296, -0.00917389, -0.02573772],\n",
       "           [-0.02030669,  0.04965982,  0.04846904, -0.01126434, -0.01379744],\n",
       "           [-0.02958877, -0.01639066, -0.01529663, -0.01842348, -0.03991101],\n",
       "           [ 0.04891438, -0.02049774,  0.00446290, -0.04730302,  0.01432705],\n",
       "           [-0.01785528, -0.02545845,  0.03913373,  0.01846999,  0.01173422]],\n",
       " \n",
       "          [[-0.02472779,  0.00808479,  0.02148593,  0.00663550, -0.02900436],\n",
       "           [ 0.02233103, -0.02804164,  0.01376319, -0.02574712, -0.03981342],\n",
       "           [-0.02266576,  0.02383001, -0.03888281, -0.04907761, -0.03677986],\n",
       "           [-0.01596363,  0.00714850, -0.02569730, -0.00745622, -0.03932735],\n",
       "           [ 0.00869957, -0.01816930,  0.03564770,  0.02103078,  0.03564799]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.00835562, -0.01191054,  0.03593649,  0.02168599, -0.04005540],\n",
       "           [-0.02205809, -0.04919634,  0.02625826, -0.03838865,  0.02325337],\n",
       "           [-0.02950822,  0.04974038,  0.01515156,  0.04524561, -0.04768644],\n",
       "           [-0.00278499, -0.04834276,  0.01963132,  0.04211095,  0.03148920],\n",
       "           [-0.02803590, -0.02419689,  0.00381729,  0.00230137, -0.03078842]],\n",
       " \n",
       "          [[ 0.02523269, -0.01176460,  0.02516811, -0.00633560, -0.04065106],\n",
       "           [-0.01187899,  0.01993819,  0.01466681,  0.04481675,  0.01907585],\n",
       "           [-0.04706034, -0.03656179,  0.00287133,  0.03545195, -0.02022290],\n",
       "           [ 0.00582994,  0.02716434,  0.02944685,  0.02003944,  0.03484735],\n",
       "           [-0.03171612, -0.01627943, -0.01152605,  0.03905791, -0.01459445]],\n",
       " \n",
       "          [[-0.00945833, -0.03256663,  0.02606357,  0.02517397, -0.03155109],\n",
       "           [ 0.04221470,  0.02013618, -0.02255434,  0.03054359, -0.04494134],\n",
       "           [ 0.02349376, -0.00699493, -0.04266170,  0.00951594, -0.04864363],\n",
       "           [ 0.01481317, -0.03688540, -0.02658950, -0.01730952, -0.04086658],\n",
       "           [-0.01949162,  0.02449184, -0.00359545, -0.04382975, -0.02804239]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]],\n",
       " \n",
       "          [[ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000],\n",
       "           [ 0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00000000]]]]),\n",
       " tensor([ 0.02217983,  0.00000000,  0.00000000,  0.00637631,  0.03472879,\n",
       "         -0.02956793,  0.00588489,  0.00000000,  0.00000000, -0.00312945,\n",
       "         -0.00464483,  0.01808250, -0.02212323,  0.01449610, -0.03525970,\n",
       "          0.01547724, -0.00331644, -0.02268236,  0.00000000,  0.00000000,\n",
       "          0.00000000,  0.00000000,  0.00000000,  0.02081930, -0.02428955,\n",
       "         -0.00265456, -0.01113445,  0.00550089,  0.02498941,  0.00000000,\n",
       "          0.00000000,  0.00000000,  0.00337967,  0.00000000, -0.02221692,\n",
       "          0.00000000,  0.00689282,  0.00000000,  0.00000000,  0.00000000,\n",
       "          0.00000000,  0.00977176, -0.00435882, -0.00644673,  0.00000000,\n",
       "          0.00000000,  0.00000000,  0.00000000,  0.00000000,  0.00695485,\n",
       "          0.00212647,  0.00000000,  0.00000000,  0.00000000,  0.00000000,\n",
       "          0.02130770,  0.01749767,  0.00000000, -0.01548645,  0.00863162,\n",
       "          0.00000000,  0.00000000,  0.00000000,  0.00000000]),\n",
       " tensor([[ 0.00000000,  0.00000000,  0.00000000,  ...,  0.00000000,\n",
       "           0.00000000,  0.00000000],\n",
       "         [ 0.00000000,  0.00000000,  0.00000000,  ...,  0.00000000,\n",
       "           0.00000000,  0.00000000],\n",
       "         [ 0.00158135,  0.00000000,  0.00000000,  ...,  0.00000000,\n",
       "           0.00000000,  0.00000000],\n",
       "         ...,\n",
       "         [ 0.00000000,  0.00000000,  0.00000000,  ...,  0.00000000,\n",
       "           0.00000000,  0.00000000],\n",
       "         [-0.02524152,  0.00000000,  0.00000000,  ...,  0.00000000,\n",
       "           0.00000000,  0.00000000],\n",
       "         [ 0.00000000,  0.00000000,  0.00000000,  ...,  0.00000000,\n",
       "           0.00000000,  0.00000000]]),\n",
       " tensor([ 0.00000000,  0.00000000, -0.01297916,  ...,  0.00000000,\n",
       "         -0.00301304,  0.00000000]),\n",
       " tensor([[ 0.00000000,  0.00000000, -0.04944493,  ...,  0.00000000,\n",
       "           0.01063192,  0.00000000],\n",
       "         [ 0.00000000,  0.00000000,  0.04699730,  ...,  0.00000000,\n",
       "          -0.01727010,  0.00000000],\n",
       "         [ 0.00000000,  0.00000000,  0.03309260,  ...,  0.00000000,\n",
       "          -0.02077681,  0.00000000],\n",
       "         ...,\n",
       "         [ 0.00000000,  0.00000000, -0.04754692,  ...,  0.00000000,\n",
       "           0.01090622,  0.00000000],\n",
       "         [ 0.00000000,  0.00000000, -0.01236754,  ...,  0.00000000,\n",
       "           0.00117807,  0.00000000],\n",
       "         [ 0.00000000,  0.00000000, -0.04754427,  ...,  0.00000000,\n",
       "          -0.04900561,  0.00000000]]),\n",
       " tensor([ 0.02143156,  0.01381432,  0.00387459, -0.02038633,  0.01178818,\n",
       "         -0.01429529,  0.00315682,  0.02117294,  0.00457302, -0.01889233,\n",
       "         -0.01693512,  0.00934116, -0.01507885, -0.01363308, -0.00236599,\n",
       "          0.01461798,  0.01631573, -0.01159699, -0.01032418,  0.01582181,\n",
       "          0.01502327,  0.01530431, -0.00288657, -0.00062812, -0.01058813,\n",
       "          0.00327253, -0.00166085,  0.01365088,  0.00815511,  0.00586184,\n",
       "          0.00382529, -0.01635706,  0.00031669,  0.00854211,  0.01498780,\n",
       "          0.01240762,  0.01208633, -0.01642621, -0.00610383,  0.00826711,\n",
       "         -0.01692472, -0.02107532,  0.00083822, -0.01903831, -0.00500334,\n",
       "         -0.00493069,  0.02054951,  0.01609197,  0.00944290, -0.01783982,\n",
       "          0.00562793,  0.00268731, -0.01557553, -0.00234084,  0.01872586,\n",
       "          0.01755990, -0.00559419,  0.01464419,  0.00688451,  0.01427543,\n",
       "         -0.00751715,  0.00676684])]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunedModel2 = prune_model(originalModel.copy(), str_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.04844368,  0.05829063,  0.06482986, -0.00037938,  0.03582773],\n",
       "           [-0.04473288,  0.03160680, -0.07192211,  0.04808041, -0.01475582],\n",
       "           [-0.04021096, -0.01238550,  0.07502086,  0.02516533,  0.04875748],\n",
       "           [-0.08481959,  0.03014215,  0.06911427, -0.02099419,  0.00149267],\n",
       "           [-0.05584396, -0.05114162, -0.08379941, -0.07522546,  0.00803423]]],\n",
       " \n",
       " \n",
       "         [[[-0.01890411,  0.02716055,  0.08087714,  0.06115712,  0.08462429],\n",
       "           [ 0.03856171,  0.06971835,  0.08150141,  0.02088659, -0.04605213],\n",
       "           [ 0.06806611,  0.05744293,  0.08113788, -0.04898061, -0.02105553],\n",
       "           [ 0.01540595,  0.04489534,  0.03256555,  0.03316144, -0.06504034],\n",
       "           [ 0.02001496,  0.07980520, -0.06566805, -0.01010335, -0.04405257]]],\n",
       " \n",
       " \n",
       "         [[[ 0.07423592, -0.05125437, -0.06619664, -0.01274159,  0.01021489],\n",
       "           [-0.06276517,  0.08011705,  0.03748520, -0.06229507,  0.06602916],\n",
       "           [ 0.00473219, -0.05548393, -0.02807406, -0.01014290, -0.07985185],\n",
       "           [ 0.07959700, -0.02171353, -0.01953296,  0.00587820,  0.03903677],\n",
       "           [ 0.06884764, -0.05712325,  0.07156454, -0.07628807,  0.05639188]]],\n",
       " \n",
       " \n",
       "         [[[-0.06754114,  0.03935809, -0.04799566, -0.01528876,  0.00287569],\n",
       "           [-0.01738717, -0.00191532,  0.01011837, -0.05364234,  0.06689110],\n",
       "           [-0.08034866, -0.06441347,  0.04701412,  0.05509371, -0.06936031],\n",
       "           [ 0.05497888, -0.06121850,  0.01623888,  0.03239373,  0.02523666],\n",
       "           [-0.03764357,  0.00432211, -0.01560474,  0.06259587,  0.00776463]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00577649, -0.02641816,  0.02020431,  0.05597195, -0.01189048],\n",
       "           [-0.03963581,  0.01025723, -0.00546320, -0.04932800,  0.04118632],\n",
       "           [-0.05362326,  0.02406134, -0.04692725, -0.04587569, -0.04224141],\n",
       "           [-0.06880878, -0.05275637,  0.00910056,  0.04267028, -0.07408337],\n",
       "           [ 0.03213961,  0.03789078,  0.08015665,  0.01903722,  0.01450763]]],\n",
       " \n",
       " \n",
       "         [[[-0.08465520,  0.07454690,  0.06946269, -0.03360638,  0.06622022],\n",
       "           [ 0.03983735, -0.05692500, -0.02909494, -0.04371936,  0.06108961],\n",
       "           [-0.03009411,  0.07667984,  0.01887979, -0.02512785, -0.01475886],\n",
       "           [ 0.03284105,  0.07301390, -0.07120478, -0.04100738, -0.00721172],\n",
       "           [ 0.03112799, -0.00711057,  0.04948820, -0.00047868,  0.04193681]]],\n",
       " \n",
       " \n",
       "         [[[-0.05388076,  0.00589657, -0.05041185,  0.01192077, -0.03288574],\n",
       "           [ 0.01442005, -0.03042192, -0.05022196,  0.07557860, -0.02856341],\n",
       "           [ 0.05612265,  0.02085792, -0.05537435, -0.02428157,  0.03604636],\n",
       "           [ 0.02536012,  0.03111135, -0.06142353,  0.04804616, -0.04240496],\n",
       "           [-0.03434419,  0.06945524, -0.03232203,  0.02651215,  0.02767710]]],\n",
       " \n",
       " \n",
       "         [[[ 0.01109114, -0.02808629, -0.07547945, -0.06319402,  0.03603935],\n",
       "           [-0.06041022, -0.03148511,  0.06864426,  0.02289152, -0.03988709],\n",
       "           [-0.02269678, -0.06778874,  0.02224734,  0.02577373, -0.01994468],\n",
       "           [ 0.04987787, -0.05473779,  0.06565763, -0.03377686,  0.06155589],\n",
       "           [ 0.03145383,  0.00703356,  0.01378154, -0.01791712, -0.07073265]]],\n",
       " \n",
       " \n",
       "         [[[ 0.08013551,  0.06117599,  0.04650989, -0.00887921, -0.06953639],\n",
       "           [-0.03834939, -0.07710607,  0.00814315, -0.03941404, -0.07592808],\n",
       "           [ 0.00578756, -0.07332635,  0.02186833,  0.05916052, -0.01729552],\n",
       "           [ 0.06298804,  0.00852334,  0.07490267, -0.02819524,  0.07120961],\n",
       "           [ 0.01009007, -0.03477889,  0.03629442, -0.01319641,  0.01109047]]],\n",
       " \n",
       " \n",
       "         [[[ 0.03615171, -0.08280973,  0.01586232, -0.03505780, -0.06819306],\n",
       "           [-0.06286940,  0.02794629, -0.06170376, -0.02201644,  0.02683395],\n",
       "           [-0.07539003,  0.06652088, -0.05006012,  0.03750464,  0.00707820],\n",
       "           [-0.04170536, -0.03093399, -0.04081349,  0.03845838, -0.02065197],\n",
       "           [ 0.08289707, -0.06552950, -0.05898034,  0.02122417, -0.03152861]]],\n",
       " \n",
       " \n",
       "         [[[ 0.06366250, -0.07887692, -0.01404854,  0.02571982, -0.05706216],\n",
       "           [ 0.03476699, -0.02158213,  0.03485905, -0.06350388,  0.07559642],\n",
       "           [ 0.00384090, -0.03791607, -0.03120488, -0.06149527,  0.05171648],\n",
       "           [-0.06841124,  0.07287371, -0.03279089, -0.02676497, -0.03308035],\n",
       "           [-0.01704048,  0.07184540,  0.06542279, -0.00922586,  0.02842392]]],\n",
       " \n",
       " \n",
       "         [[[-0.00962681,  0.01798947, -0.05385663, -0.00919165,  0.06446391],\n",
       "           [ 0.01132596,  0.07432026, -0.02405516,  0.07763150, -0.06637014],\n",
       "           [-0.03515239,  0.04629381, -0.05499325, -0.02602571, -0.04011011],\n",
       "           [-0.01058330,  0.01810910, -0.00145596,  0.08193238,  0.07656749],\n",
       "           [-0.00410071,  0.01400820, -0.01848925, -0.04705951,  0.03935453]]],\n",
       " \n",
       " \n",
       "         [[[ 0.03613886,  0.07836822,  0.05346386, -0.03086790,  0.00569790],\n",
       "           [ 0.03021947, -0.04793297,  0.03359801,  0.07600518, -0.05837722],\n",
       "           [-0.04578085, -0.02408153,  0.08340459,  0.05142863,  0.07707687],\n",
       "           [ 0.06645714,  0.03505095,  0.07900323, -0.05538959,  0.04938056],\n",
       "           [ 0.04285678,  0.04296936,  0.00720181, -0.02149013, -0.08491769]]],\n",
       " \n",
       " \n",
       "         [[[-0.01323974, -0.06717028, -0.07947886,  0.02627150,  0.05384852],\n",
       "           [-0.04572500, -0.02581372,  0.04519613,  0.08186376, -0.00093238],\n",
       "           [ 0.03411610, -0.03626975, -0.02962031, -0.06703740, -0.07878109],\n",
       "           [ 0.01233320, -0.06445105, -0.01093302,  0.05362776, -0.08102603],\n",
       "           [ 0.05634393,  0.07217932, -0.06816791, -0.01164497, -0.06031089]]],\n",
       " \n",
       " \n",
       "         [[[-0.05765337, -0.02885115,  0.06977578,  0.01063229,  0.06793243],\n",
       "           [ 0.05518994,  0.05985075, -0.03168412, -0.06005383,  0.04295310],\n",
       "           [ 0.03326801,  0.02362899, -0.08027796, -0.05976363,  0.02829885],\n",
       "           [ 0.04408552,  0.00417942,  0.02964408, -0.02367242,  0.05470517],\n",
       "           [-0.01507925, -0.04117820,  0.02082251, -0.03099097,  0.07561387]]],\n",
       " \n",
       " \n",
       "         [[[-0.00229688, -0.07165018, -0.02414665, -0.06535555, -0.02020578],\n",
       "           [-0.01517975, -0.07440664,  0.02669106, -0.04399443, -0.03714638],\n",
       "           [-0.06686238,  0.04749191, -0.08503105, -0.07942209,  0.05112445],\n",
       "           [ 0.01947643, -0.05260486, -0.01308265,  0.07420972,  0.02910350],\n",
       "           [-0.07539406,  0.05593477,  0.02612317, -0.07259049,  0.06798829]]]]),\n",
       " tensor([ 0.11684166,  0.11655416,  0.17319210,  0.09416012, -0.15880871,\n",
       "          0.09444441,  0.14867331, -0.17493442,  0.00552233, -0.09209271,\n",
       "         -0.13923287,  0.09733601, -0.13362989, -0.07768793,  0.10278414,\n",
       "          0.11368717]),\n",
       " tensor([[[[-4.03315239e-02, -3.95335741e-02, -2.98629645e-02, -9.17389244e-03,\n",
       "            -2.57377215e-02],\n",
       "           [-2.03066897e-02,  4.96598221e-02,  4.84690405e-02, -1.12643428e-02,\n",
       "            -1.37974396e-02],\n",
       "           [-2.95887720e-02, -1.63906589e-02, -1.52966268e-02, -1.84234753e-02,\n",
       "            -3.99110131e-02],\n",
       "           [ 4.89143766e-02, -2.04977393e-02,  4.46289778e-03, -4.73030210e-02,\n",
       "             1.43270455e-02],\n",
       "           [-1.78552791e-02, -2.54584495e-02,  3.91337313e-02,  1.84699930e-02,\n",
       "             1.17342249e-02]],\n",
       " \n",
       "          [[-2.47277915e-02,  8.08479264e-03,  2.14859284e-02,  6.63549826e-03,\n",
       "            -2.90043596e-02],\n",
       "           [ 2.23310329e-02, -2.80416366e-02,  1.37631930e-02, -2.57471204e-02,\n",
       "            -3.98134179e-02],\n",
       "           [-2.26657577e-02,  2.38300078e-02, -3.88828143e-02, -4.90776114e-02,\n",
       "            -3.67798582e-02],\n",
       "           [-1.59636252e-02,  7.14850426e-03, -2.56972965e-02, -7.45622069e-03,\n",
       "            -3.93273532e-02],\n",
       "           [ 8.69956613e-03, -1.81692950e-02,  3.56477015e-02,  2.10307799e-02,\n",
       "             3.56479920e-02]],\n",
       " \n",
       "          [[ 6.31297380e-03, -2.15562340e-02,  1.22191198e-02, -3.84455919e-03,\n",
       "             4.45646979e-02],\n",
       "           [ 9.16256756e-03,  3.70139368e-02, -1.82454959e-02,  2.57450230e-02,\n",
       "             3.38146426e-02],\n",
       "           [-4.79011126e-02,  1.85020268e-04, -3.76070142e-02,  3.51675786e-02,\n",
       "             4.88388799e-02],\n",
       "           [ 3.71677391e-02, -4.71779779e-02,  4.20298316e-02, -1.02318823e-02,\n",
       "             3.67753096e-02],\n",
       "           [ 1.58537291e-02,  2.40145661e-02,  2.95594074e-02, -2.00541373e-02,\n",
       "             3.42954323e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.35562497e-03, -1.19105391e-02,  3.59364860e-02,  2.16859914e-02,\n",
       "            -4.00554016e-02],\n",
       "           [-2.20580939e-02, -4.91963401e-02,  2.62582637e-02, -3.83886471e-02,\n",
       "             2.32533701e-02],\n",
       "           [-2.95082163e-02,  4.97403778e-02,  1.51515640e-02,  4.52456139e-02,\n",
       "            -4.76864353e-02],\n",
       "           [-2.78498977e-03, -4.83427607e-02,  1.96313150e-02,  4.21109535e-02,\n",
       "             3.14891972e-02],\n",
       "           [-2.80359033e-02, -2.41968874e-02,  3.81729007e-03,  2.30136514e-03,\n",
       "            -3.07884216e-02]],\n",
       " \n",
       "          [[ 2.52326913e-02, -1.17646046e-02,  2.51681097e-02, -6.33560494e-03,\n",
       "            -4.06510606e-02],\n",
       "           [-1.18789896e-02,  1.99381895e-02,  1.46668144e-02,  4.48167510e-02,\n",
       "             1.90758519e-02],\n",
       "           [-4.70603406e-02, -3.65617871e-02,  2.87133455e-03,  3.54519524e-02,\n",
       "            -2.02229023e-02],\n",
       "           [ 5.82994148e-03,  2.71643437e-02,  2.94468515e-02,  2.00394355e-02,\n",
       "             3.48473452e-02],\n",
       "           [-3.17161158e-02, -1.62794292e-02, -1.15260482e-02,  3.90579142e-02,\n",
       "            -1.45944543e-02]],\n",
       " \n",
       "          [[-9.45833325e-03, -3.25666294e-02,  2.60635652e-02,  2.51739733e-02,\n",
       "            -3.15510929e-02],\n",
       "           [ 4.22146954e-02,  2.01361813e-02, -2.25543380e-02,  3.05435918e-02,\n",
       "            -4.49413434e-02],\n",
       "           [ 2.34937631e-02, -6.99492544e-03, -4.26617041e-02,  9.51594114e-03,\n",
       "            -4.86436263e-02],\n",
       "           [ 1.48131661e-02, -3.68854031e-02, -2.65895016e-02, -1.73095241e-02,\n",
       "            -4.08665761e-02],\n",
       "           [-1.94916185e-02,  2.44918354e-02, -3.59544903e-03, -4.38297503e-02,\n",
       "            -2.80423947e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.25696675e-02, -1.04387887e-02, -4.13780659e-03,  3.45369056e-03,\n",
       "            -7.40030408e-03],\n",
       "           [ 1.51675008e-02, -3.18543240e-03, -1.10590681e-02,  7.07002357e-03,\n",
       "            -8.64076614e-03],\n",
       "           [ 2.15841271e-02,  1.36826746e-02,  3.82020809e-02, -3.12037896e-02,\n",
       "             3.31994630e-02],\n",
       "           [ 3.00670452e-02,  3.09389085e-03, -3.69851291e-02, -1.02243200e-02,\n",
       "             4.93442267e-03],\n",
       "           [ 4.61988784e-02, -2.90802605e-02,  1.19016320e-03, -4.51187752e-02,\n",
       "            -2.20634695e-02]],\n",
       " \n",
       "          [[-2.54121013e-02, -3.22871506e-02,  4.48078327e-02,  1.83523931e-02,\n",
       "            -3.40718031e-02],\n",
       "           [ 2.97350474e-02,  2.33109109e-02,  9.08561423e-03, -2.65770555e-02,\n",
       "            -4.43867333e-02],\n",
       "           [ 1.16981678e-02, -4.88229841e-03,  4.87619676e-02,  6.98368996e-03,\n",
       "             1.61697343e-03],\n",
       "           [ 3.12759466e-02, -1.40247159e-02,  3.72512676e-02, -4.65144478e-02,\n",
       "            -4.34400253e-02],\n",
       "           [-4.50109616e-02, -3.38304043e-03, -2.98862588e-02, -1.94154810e-02,\n",
       "            -2.87367236e-02]],\n",
       " \n",
       "          [[ 3.10561098e-02,  3.39319184e-03, -3.61033678e-02, -4.76166196e-02,\n",
       "             2.84009762e-02],\n",
       "           [-4.63263355e-02,  1.02114677e-03,  1.15901306e-02, -4.78313975e-02,\n",
       "            -1.59567893e-02],\n",
       "           [-9.43582505e-03, -2.82951053e-02, -3.02388370e-02, -3.42005342e-02,\n",
       "             3.20210122e-02],\n",
       "           [ 4.85270359e-02, -3.24989781e-02, -4.81059812e-02,  3.99455167e-02,\n",
       "             3.70685346e-02],\n",
       "           [ 1.34196915e-02, -1.44861825e-02, -2.08520237e-02,  4.27427925e-02,\n",
       "             4.21305038e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.37738585e-02, -1.95858534e-02,  1.36852264e-03, -4.94178645e-02,\n",
       "             4.89295386e-02],\n",
       "           [ 3.40732969e-02, -2.99575161e-02,  4.79069985e-02,  4.98447604e-02,\n",
       "            -1.85025446e-02],\n",
       "           [-3.63964029e-02, -3.94126475e-02, -4.52126265e-02,  2.32465155e-02,\n",
       "             2.11712308e-02],\n",
       "           [ 4.08518128e-02, -2.16750987e-02, -4.29030135e-03, -3.00613288e-02,\n",
       "             2.37189047e-02],\n",
       "           [-1.28930062e-03, -1.31884106e-02,  4.27361690e-02, -1.50061734e-02,\n",
       "            -3.70648205e-02]],\n",
       " \n",
       "          [[-3.20975371e-02, -3.31209227e-02,  1.53994597e-02, -3.42339277e-03,\n",
       "             3.21764983e-02],\n",
       "           [ 4.36653830e-02, -3.70254442e-02,  1.72118582e-02,  3.13818790e-02,\n",
       "             3.76363285e-02],\n",
       "           [-8.54783505e-03,  4.95092608e-02, -4.56463359e-02, -3.79644744e-02,\n",
       "             4.30463292e-02],\n",
       "           [-3.02691814e-02, -1.45920031e-02, -3.60494666e-02, -2.84324419e-02,\n",
       "            -1.49592459e-02],\n",
       "           [ 4.06762399e-02, -2.28044987e-02, -3.05731427e-02,  4.33676280e-02,\n",
       "             5.42277098e-03]],\n",
       " \n",
       "          [[ 2.32576579e-03, -1.46849155e-02,  4.04587500e-02,  2.88830586e-02,\n",
       "             4.25060429e-02],\n",
       "           [ 3.37138511e-02,  1.98028423e-02, -1.08003616e-04,  2.90715359e-02,\n",
       "             3.59620266e-02],\n",
       "           [-2.77070832e-02,  7.82582909e-03,  3.34310532e-03, -4.08313051e-02,\n",
       "             8.99651647e-03],\n",
       "           [ 7.97625631e-03, -2.90689953e-02, -4.99396399e-03,  5.05407900e-03,\n",
       "             2.41310857e-02],\n",
       "           [-4.37428616e-02,  2.38744356e-02,  1.07408054e-02,  1.84747539e-02,\n",
       "            -1.90304946e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.82625316e-02, -3.25064138e-02, -4.87808660e-02, -3.40646282e-02,\n",
       "            -4.02546227e-02],\n",
       "           [ 1.03713162e-02, -3.12366672e-02, -1.23103745e-02,  1.32877380e-04,\n",
       "            -4.37919013e-02],\n",
       "           [ 1.44933499e-02,  4.89843227e-02,  2.12045759e-03,  3.08626555e-02,\n",
       "            -1.46526843e-03],\n",
       "           [-3.49964984e-02,  7.93796033e-03,  1.27390809e-02,  1.43203177e-02,\n",
       "             1.98125839e-03],\n",
       "           [ 2.34246217e-02,  1.84322633e-02, -3.81231606e-02,  3.81505229e-02,\n",
       "            -4.00831327e-02]],\n",
       " \n",
       "          [[ 1.43749155e-02,  2.43590400e-03,  4.40084077e-02, -4.91566360e-02,\n",
       "             2.08278485e-02],\n",
       "           [ 1.67001672e-02,  4.40744720e-02, -1.09012797e-03, -3.47986035e-02,\n",
       "             1.32957101e-03],\n",
       "           [-2.81122029e-02,  2.80742757e-02, -2.01865677e-02, -4.94883731e-02,\n",
       "             1.46693997e-02],\n",
       "           [ 3.75708938e-03, -3.95971462e-02,  1.32859088e-02, -4.46882024e-02,\n",
       "             2.32019536e-02],\n",
       "           [ 9.20664147e-03, -3.60998623e-02, -3.37215289e-02, -4.90466133e-02,\n",
       "            -7.90029764e-04]],\n",
       " \n",
       "          [[-3.92707437e-03,  5.95241785e-03,  4.67916094e-02,  3.26560698e-02,\n",
       "            -4.45829406e-02],\n",
       "           [-2.36713942e-02,  2.14270838e-02,  1.59135796e-02, -3.40709463e-02,\n",
       "            -1.86544880e-02],\n",
       "           [-4.31945920e-03, -4.85824645e-02, -2.46984549e-02,  4.69389670e-02,\n",
       "            -1.92626957e-02],\n",
       "           [ 2.95146443e-02, -4.69688773e-02, -2.37048790e-03,  1.92851536e-02,\n",
       "            -9.26820561e-03],\n",
       "           [-2.15536114e-02, -9.49217752e-03, -2.48650555e-02, -4.32865508e-02,\n",
       "            -2.16320157e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.98735739e-02, -1.94999166e-02,  4.02791537e-02,  1.31398253e-02,\n",
       "             3.59267332e-02],\n",
       "           [ 1.50231756e-02, -7.27136061e-03, -4.40312624e-02, -3.80733199e-02,\n",
       "             2.68643238e-02],\n",
       "           [-2.63939686e-02,  1.08400062e-02,  9.12917405e-03,  4.49388437e-02,\n",
       "            -1.23636052e-02],\n",
       "           [ 2.52319165e-02,  2.92661302e-02,  3.67150269e-02, -6.16865233e-03,\n",
       "            -4.97883074e-02],\n",
       "           [-4.75391150e-02,  4.65439893e-02, -3.65848020e-02, -1.67741589e-02,\n",
       "            -3.04215383e-02]],\n",
       " \n",
       "          [[-4.74858396e-02, -4.32325527e-03, -1.29068792e-02, -9.46835801e-03,\n",
       "            -2.41767596e-02],\n",
       "           [ 4.94489260e-02, -2.46138759e-02, -1.83927715e-02,  3.46053652e-02,\n",
       "             1.48482956e-02],\n",
       "           [-1.32388622e-03,  2.46859714e-03,  3.60797830e-02,  3.68432812e-02,\n",
       "            -6.52071089e-03],\n",
       "           [ 1.82790793e-02, -1.76367983e-02,  4.93413545e-02, -4.03635204e-05,\n",
       "            -4.38972525e-02],\n",
       "           [-9.12684202e-03,  9.84088331e-03,  1.26734376e-05, -4.17571515e-04,\n",
       "            -9.51423496e-03]],\n",
       " \n",
       "          [[ 1.20495260e-02, -2.22382974e-02,  3.02896164e-02,  4.73572426e-02,\n",
       "            -4.97785285e-02],\n",
       "           [ 4.55068387e-02, -4.77253087e-02,  7.13765621e-05,  3.38324048e-02,\n",
       "             4.22459096e-04],\n",
       "           [ 4.22484912e-02, -2.29093079e-02,  4.93313260e-02, -4.88414541e-02,\n",
       "            -4.43807542e-02],\n",
       "           [-2.45469566e-02, -2.83456594e-03, -9.77836549e-04, -1.37412176e-02,\n",
       "             1.83024965e-02],\n",
       "           [ 4.25094999e-02, -4.74724732e-02,  1.83732845e-02, -2.97286995e-02,\n",
       "             4.29847278e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.52962057e-02,  9.92845371e-03,  1.40016265e-02,  2.80976333e-02,\n",
       "            -4.54588905e-02],\n",
       "           [-2.19715368e-02, -3.80310006e-02, -2.80583389e-02,  1.91396885e-02,\n",
       "             4.60244305e-02],\n",
       "           [-4.68863919e-03,  4.17862870e-02, -3.71746719e-05, -2.50941701e-02,\n",
       "             1.80904940e-03],\n",
       "           [ 4.23177592e-02, -3.60325687e-02, -1.77584291e-02,  2.93588676e-02,\n",
       "            -1.00323930e-02],\n",
       "           [-5.11358306e-03, -2.66157631e-02,  1.09638683e-02, -2.56069601e-02,\n",
       "             2.32272409e-02]],\n",
       " \n",
       "          [[ 5.36856055e-03, -2.13915166e-02, -1.16567798e-02, -4.19975221e-02,\n",
       "             3.21592651e-02],\n",
       "           [-2.52778083e-03,  9.11875442e-03,  1.37839802e-02,  2.04532258e-02,\n",
       "            -1.29147060e-02],\n",
       "           [-1.44440755e-02, -3.19744870e-02,  9.11066681e-03,  2.09744386e-02,\n",
       "             3.25749107e-02],\n",
       "           [ 1.01552196e-02,  3.60486098e-02,  4.01942320e-02,  4.30043824e-02,\n",
       "             1.46196298e-02],\n",
       "           [-4.36899811e-03,  2.62134783e-02, -4.03794274e-02, -4.27711755e-03,\n",
       "            -4.18207869e-02]],\n",
       " \n",
       "          [[ 4.99195792e-02, -1.97075959e-02, -4.11731191e-02,  3.84863056e-02,\n",
       "             4.77357469e-02],\n",
       "           [-2.13710852e-02,  2.98190229e-02,  4.47240062e-02, -4.99336086e-02,\n",
       "             2.96196677e-02],\n",
       "           [-1.73582062e-02,  2.88821496e-02, -2.53403187e-03,  2.63200589e-02,\n",
       "             2.64208131e-02],\n",
       "           [-4.81825434e-02,  2.42774822e-02,  2.51894481e-02, -2.04027239e-02,\n",
       "             4.83554341e-02],\n",
       "           [-2.93689016e-02,  1.14868097e-02, -2.09742077e-02,  2.78216712e-02,\n",
       "             4.83703949e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.56445932e-03,  4.81776781e-02,  1.48372762e-02, -9.41595435e-03,\n",
       "            -3.75149772e-02],\n",
       "           [ 3.59345041e-02,  2.44318508e-02, -3.66287827e-02, -6.30559772e-03,\n",
       "             2.64746696e-03],\n",
       "           [ 1.66847371e-02,  2.05258094e-02,  2.27935351e-02,  3.79987471e-02,\n",
       "             3.78049947e-02],\n",
       "           [ 1.95747353e-02,  2.85799764e-02,  4.44179811e-02, -1.90746021e-02,\n",
       "             4.79595177e-02],\n",
       "           [ 4.60698865e-02,  2.24230029e-02, -4.60387282e-02, -3.62638310e-02,\n",
       "             4.86057140e-02]],\n",
       " \n",
       "          [[ 8.65886733e-03,  3.37373093e-03,  4.23180796e-02, -3.31929103e-02,\n",
       "            -9.39597562e-03],\n",
       "           [-1.87596027e-02,  4.50898334e-03,  2.45530121e-02,  4.07921709e-02,\n",
       "            -1.02808885e-02],\n",
       "           [ 1.28365718e-02,  1.57916956e-02,  2.29895115e-03, -2.95153316e-02,\n",
       "             5.97239286e-03],\n",
       "           [-2.98981201e-02,  1.91371180e-02, -4.99265492e-02,  3.19645740e-02,\n",
       "             1.93392821e-02],\n",
       "           [ 3.81079055e-02,  1.97080933e-02,  1.07335225e-02, -4.47916947e-02,\n",
       "             1.77308954e-02]],\n",
       " \n",
       "          [[-3.58796902e-02,  3.93172763e-02, -1.62100680e-02,  4.95495684e-02,\n",
       "            -4.81642745e-02],\n",
       "           [-4.37251925e-02, -3.09694298e-02,  4.05240059e-03, -8.36970657e-03,\n",
       "             1.71430148e-02],\n",
       "           [-1.25654042e-04, -1.61752105e-05, -4.20808494e-02,  2.82008573e-03,\n",
       "            -2.77819522e-02],\n",
       "           [-4.52606343e-02,  2.43311040e-02,  1.38945021e-02, -2.90193502e-02,\n",
       "            -2.40382850e-02],\n",
       "           [-3.75847928e-02, -9.86798480e-03,  4.54247855e-02, -2.59257853e-02,\n",
       "             4.78356667e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.56357358e-02, -1.09195113e-02, -2.32345350e-02,  1.41537525e-02,\n",
       "            -1.66138336e-02],\n",
       "           [-4.52469066e-02, -2.15313956e-03, -4.91458438e-02, -3.52161936e-02,\n",
       "             1.98902935e-03],\n",
       "           [-3.03796232e-02, -3.19493935e-03,  4.90126498e-02, -3.88469771e-02,\n",
       "            -2.01075673e-02],\n",
       "           [ 1.69773437e-02,  2.69422866e-02,  3.92888822e-02, -2.22725105e-02,\n",
       "             4.50611860e-03],\n",
       "           [-3.70849445e-02,  4.63471673e-02,  2.58202814e-02,  2.39257775e-02,\n",
       "             3.43943052e-02]],\n",
       " \n",
       "          [[-3.72983143e-02,  2.94563212e-02, -9.20745730e-03,  3.38705368e-02,\n",
       "             9.33066010e-03],\n",
       "           [ 1.00471489e-02,  1.41196810e-02,  1.18742511e-03,  4.65326421e-02,\n",
       "             4.92661931e-02],\n",
       "           [-2.96917018e-02,  1.07766800e-02, -8.34878534e-03,  1.44877546e-02,\n",
       "            -3.67795713e-02],\n",
       "           [ 3.15277018e-02, -2.63988432e-02, -2.04643141e-02,  1.16716027e-02,\n",
       "             3.48382108e-02],\n",
       "           [-2.70028953e-02,  2.95920484e-02, -4.68791910e-02, -3.34479138e-02,\n",
       "            -4.39047776e-02]],\n",
       " \n",
       "          [[-8.06305557e-03, -3.75107341e-02,  3.92324589e-02, -4.30973731e-02,\n",
       "            -4.87187579e-02],\n",
       "           [ 4.85762395e-02, -1.82381682e-02, -6.88276440e-03, -1.46727152e-02,\n",
       "            -1.09571964e-03],\n",
       "           [ 4.52248566e-02, -1.84579678e-02,  3.02116908e-02, -1.95680261e-02,\n",
       "             4.74889092e-02],\n",
       "           [ 1.68096758e-02, -1.79036632e-02, -7.00265914e-03, -4.95882519e-02,\n",
       "             4.13418971e-02],\n",
       "           [-3.13053280e-02, -8.14275071e-03, -3.77183966e-02, -1.18581206e-03,\n",
       "            -1.69116743e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.43565708e-03, -1.32160261e-03,  1.57210194e-02,  2.26247646e-02,\n",
       "            -1.78693645e-02],\n",
       "           [ 2.77163200e-02, -3.73522341e-02,  5.10440022e-03,  2.16481090e-03,\n",
       "            -1.90901943e-02],\n",
       "           [-5.76404482e-03, -2.43310463e-02, -2.83631030e-02,  3.27050798e-02,\n",
       "             1.91761367e-02],\n",
       "           [-4.69473712e-02,  5.39999455e-03, -2.38061845e-02,  5.12261316e-03,\n",
       "            -1.41368099e-02],\n",
       "           [ 3.36613096e-02, -1.32881105e-04, -3.05771828e-02, -2.37831119e-02,\n",
       "             4.68349718e-02]],\n",
       " \n",
       "          [[-2.55819689e-02, -3.82896140e-03,  1.29782036e-03, -4.92634661e-02,\n",
       "             9.88768414e-03],\n",
       "           [ 1.66082047e-02, -4.14220244e-03, -4.62474003e-02, -3.17452140e-02,\n",
       "             2.58860737e-03],\n",
       "           [-1.34193301e-02,  9.07113403e-03, -3.72469127e-02,  4.13752012e-02,\n",
       "             1.48964860e-02],\n",
       "           [-3.89747545e-02, -6.99980929e-03, -2.07776427e-02,  2.45941617e-02,\n",
       "             3.72721292e-02],\n",
       "           [-3.80366631e-02,  1.34963952e-02,  3.51337530e-02,  4.98141386e-02,\n",
       "             4.22029942e-03]],\n",
       " \n",
       "          [[ 2.42654718e-02,  1.58617534e-02,  3.37898470e-02, -3.51045132e-02,\n",
       "             1.86792947e-02],\n",
       "           [-4.12206873e-02,  4.20811772e-03,  9.65685770e-03, -1.45967081e-02,\n",
       "             3.99893336e-02],\n",
       "           [-1.63233466e-02, -4.71519008e-02,  3.26990522e-02, -2.46814135e-02,\n",
       "             4.46667112e-02],\n",
       "           [ 4.15839292e-02, -2.86687370e-02, -2.43324768e-02,  1.47803500e-03,\n",
       "             4.37193178e-02],\n",
       "           [-3.09741553e-02, -1.79612264e-02,  3.34998257e-02, -2.82750372e-02,\n",
       "            -2.83651408e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.62742692e-03,  7.97676295e-03,  1.08309463e-02,  4.31422256e-02,\n",
       "             1.56528167e-02],\n",
       "           [-8.47051665e-03, -1.13012008e-02, -1.62155405e-02, -8.11431557e-03,\n",
       "            -3.46341059e-02],\n",
       "           [ 1.71391107e-02, -3.36761028e-02,  9.30289552e-03,  3.30105983e-02,\n",
       "             4.12613116e-02],\n",
       "           [ 4.84093279e-03, -4.13411856e-02, -3.97154875e-02, -3.82604226e-02,\n",
       "             4.25588600e-02],\n",
       "           [ 2.13291682e-02, -6.47366047e-03, -4.51186970e-02, -2.44201478e-02,\n",
       "             9.82625410e-03]],\n",
       " \n",
       "          [[ 3.96634676e-02, -3.39346081e-02,  3.35102417e-02, -4.23625596e-02,\n",
       "             5.61951473e-03],\n",
       "           [-4.69773412e-02, -3.90289724e-02, -1.76576562e-02, -1.82040855e-02,\n",
       "            -3.69573124e-02],\n",
       "           [-2.94161588e-03, -2.56540366e-02, -3.31716761e-02,  4.94687967e-02,\n",
       "            -2.10161097e-02],\n",
       "           [ 3.60114314e-02,  3.28296013e-02,  9.90122557e-03,  1.09024048e-02,\n",
       "            -3.87823209e-02],\n",
       "           [ 1.50176883e-03,  1.43186487e-02,  2.51659006e-03, -4.92612720e-02,\n",
       "            -8.26726481e-03]],\n",
       " \n",
       "          [[ 9.14756209e-03, -4.24392335e-02,  4.20704819e-02, -6.24656677e-03,\n",
       "            -2.08203197e-02],\n",
       "           [-4.71578017e-02,  4.98953126e-02, -1.58123896e-02, -2.66737640e-02,\n",
       "             1.52349286e-02],\n",
       "           [ 1.23915970e-02, -1.01115480e-02,  5.00499085e-03,  6.21483847e-03,\n",
       "            -2.30778754e-02],\n",
       "           [ 1.18552372e-02,  6.10898808e-03,  4.56260927e-02, -2.24065185e-02,\n",
       "             2.48820372e-02],\n",
       "           [ 1.36939101e-02,  2.43904069e-03, -3.88573855e-04, -1.36597157e-02,\n",
       "             1.55945309e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.12960334e-02,  3.84905972e-02,  2.49877535e-02, -1.39489770e-02,\n",
       "             3.49391289e-02],\n",
       "           [ 3.93060781e-02,  2.21691653e-03,  8.52349401e-03,  1.07810013e-02,\n",
       "            -3.80060375e-02],\n",
       "           [-3.06228641e-02,  1.33831613e-02,  1.38101019e-02,  1.35224797e-02,\n",
       "             4.66029681e-02],\n",
       "           [-3.57260555e-03, -1.07408874e-02,  3.24212424e-02, -9.73309949e-03,\n",
       "            -9.43829864e-03],\n",
       "           [ 1.66264512e-02,  3.77181880e-02,  4.54377383e-03,  1.30988769e-02,\n",
       "            -4.48019207e-02]],\n",
       " \n",
       "          [[-8.59125331e-03, -2.06852015e-02,  4.33386303e-02, -9.33693722e-03,\n",
       "             1.61041655e-02],\n",
       "           [-2.35086139e-02, -2.78928522e-02, -4.45857346e-02,  2.47362740e-02,\n",
       "            -4.88635115e-02],\n",
       "           [ 1.03443488e-02,  2.05242671e-02,  1.03098750e-02, -2.90022045e-03,\n",
       "             1.79846622e-02],\n",
       "           [-3.93146276e-02, -2.75554508e-03,  4.59885336e-02,  1.43417157e-02,\n",
       "             2.47847848e-02],\n",
       "           [-1.26193836e-02, -4.91255298e-02, -2.05754526e-02, -2.56716553e-02,\n",
       "            -4.27193306e-02]],\n",
       " \n",
       "          [[-3.49494107e-02, -4.50694039e-02, -4.83222269e-02,  2.59132273e-02,\n",
       "             8.18204880e-03],\n",
       "           [ 1.95369087e-02, -4.54946831e-02,  4.90846373e-02,  2.20023468e-03,\n",
       "            -1.67602226e-02],\n",
       "           [-3.34675796e-02, -2.45797634e-03,  4.64448966e-02, -4.83265929e-02,\n",
       "            -2.21639704e-02],\n",
       "           [-2.78499071e-02, -3.73857319e-02,  3.18841748e-02, -1.18741095e-02,\n",
       "             4.68831994e-02],\n",
       "           [-1.96549054e-02,  9.38579440e-03, -3.86899114e-02, -3.91495451e-02,\n",
       "            -1.00044422e-02]]]]),\n",
       " tensor([ 0.02217983,  0.00637631,  0.03472879, -0.02956793,  0.00588489,\n",
       "         -0.00312945, -0.00464483,  0.01808250, -0.02212323,  0.01449610,\n",
       "         -0.03525970,  0.01547724, -0.00331644, -0.02268236,  0.02081930,\n",
       "         -0.02428955, -0.00265456, -0.01113445,  0.00550089,  0.02498941,\n",
       "          0.00337967, -0.02221692,  0.00689282,  0.00977176, -0.00435882,\n",
       "         -0.00644673,  0.00695485,  0.00212647,  0.02130770,  0.01749767,\n",
       "         -0.01548645,  0.00863162]),\n",
       " tensor([[ 0.00158135,  0.01812871,  0.01077360,  ..., -0.00385516,\n",
       "          -0.00744742, -0.02000499],\n",
       "         [-0.03287715,  0.01729613, -0.00556781,  ..., -0.02836755,\n",
       "          -0.01846086,  0.02720107],\n",
       "         [-0.00152101, -0.03162010,  0.00836260,  ...,  0.01405087,\n",
       "           0.02195969,  0.02579539],\n",
       "         ...,\n",
       "         [-0.01760422,  0.01638416,  0.00492632,  ...,  0.02820616,\n",
       "          -0.02223752,  0.02569524],\n",
       "         [ 0.03098715,  0.00140151,  0.01630951,  ...,  0.03108574,\n",
       "           0.01332518,  0.00602887],\n",
       "         [-0.02524152, -0.03361825, -0.03147239,  ...,  0.01772230,\n",
       "           0.00559188,  0.01733040]]),\n",
       " tensor([-0.01297916,  0.01609736, -0.00395756,  ..., -0.01548178,\n",
       "          0.01299558, -0.00301304]),\n",
       " tensor([[-0.04944493,  0.04237600, -0.03978390,  ...,  0.01474394,\n",
       "           0.00369550,  0.01063192],\n",
       "         [ 0.04699730,  0.01744263,  0.02001416,  ...,  0.00474073,\n",
       "          -0.01427121, -0.01727010],\n",
       "         [ 0.03309260,  0.01584024, -0.02257191,  ..., -0.00627196,\n",
       "           0.00089609, -0.02077681],\n",
       "         ...,\n",
       "         [-0.04754692,  0.00465993,  0.04163340,  ...,  0.01278159,\n",
       "           0.03791077,  0.01090622],\n",
       "         [-0.01236754, -0.00753682,  0.00418429,  ...,  0.05112486,\n",
       "          -0.05155564,  0.00117807],\n",
       "         [-0.04754427, -0.00425624,  0.03330820,  ..., -0.00434452,\n",
       "          -0.01251196, -0.04900561]]),\n",
       " tensor([ 0.02143156,  0.01381432,  0.00387459, -0.02038633,  0.01178818,\n",
       "         -0.01429529,  0.00315682,  0.02117294,  0.00457302, -0.01889233,\n",
       "         -0.01693512,  0.00934116, -0.01507885, -0.01363308, -0.00236599,\n",
       "          0.01461798,  0.01631573, -0.01159699, -0.01032418,  0.01582181,\n",
       "          0.01502327,  0.01530431, -0.00288657, -0.00062812, -0.01058813,\n",
       "          0.00327253, -0.00166085,  0.01365088,  0.00815511,  0.00586184,\n",
       "          0.00382529, -0.01635706,  0.00031669,  0.00854211,  0.01498780,\n",
       "          0.01240762,  0.01208633, -0.01642621, -0.00610383,  0.00826711,\n",
       "         -0.01692472, -0.02107532,  0.00083822, -0.01903831, -0.00500334,\n",
       "         -0.00493069,  0.02054951,  0.01609197,  0.00944290, -0.01783982,\n",
       "          0.00562793,  0.00268731, -0.01557553, -0.00234084,  0.01872586,\n",
       "          0.01755990, -0.00559419,  0.01464419,  0.00688451,  0.01427543,\n",
       "         -0.00751715,  0.00676684])]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prunedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[prunedModel2[i].sum() - prunedModel[i].sum() for i in range(len(prunedModel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3],\n",
    "             [4, 5, 6]])\n",
    "\n",
    "indices = [0, 2, 4]\n",
    "\n",
    "for i in indices:\n",
    "    x = np.insert(x, i, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [1, 2, 3],\n",
       "       [0, 0, 0],\n",
       "       [4, 5, 6],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(x, indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTorchParamsToTF(th_np_params_):\n",
    "    th_np_params = th_np_params_.copy()\n",
    "    tf_np_params = []\n",
    "    for i, param in enumerate(th_np_params):\n",
    "        if i % 2 != 0:\n",
    "            tf_np_params.append(param)\n",
    "        elif i == 0 or i == 2:\n",
    "            tf_np_params.append(param.transpose(2, 3, 1, 0))\n",
    "        else:\n",
    "            tf_np_params.append(param.transpose())\n",
    "\n",
    "    return tf_np_params \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = [param.detach().numpy() for param in FemnistNet().parameters()]\n",
    "model_params_tf = convertTorchParamsToTF(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchParams = [param.detach().numpy() for param in model_params]\n",
    "indices_to_remove_ = [i for i in range(0, 64, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_filters_to_neuron_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6e8a567e1138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneuron_indices_to_prune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_filters_to_neuron_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_remove_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcomp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_neurons_next_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuron_indices_to_prune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_filters_to_neuron_indices' is not defined"
     ]
    }
   ],
   "source": [
    "neuron_indices_to_prune = convert_filters_to_neuron_indices(indices_to_remove_, 7)\n",
    "comp1 = remove_neurons_next_layer(model_params[4], neuron_indices_to_prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp2 = remove_filters_next_layer(model_params[4].reshape(-1, 64, 7, 7), indices_to_remove_).reshape(2048, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2048, 3136]), True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams[4].shape, (comp1 == comp2).sum() == (comp1.shape[0] * comp1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp1_tf = np.delete(model_params_tf[4].copy(), neuron_indices_to_prune, axis = 0)\n",
    "comp2_tf = np.delete(model_params_tf[4].reshape(7, 7, 64, -1), indices_to_remove_, axis = 2).reshape(-1, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01131314, -0.02805465, -0.00452592, ...,  0.03110808,\n",
       "        -0.0081866 ,  0.01150165],\n",
       "       [ 0.02661739,  0.00250652,  0.00383391, ..., -0.03372315,\n",
       "         0.03283475,  0.0042488 ],\n",
       "       [ 0.02692273,  0.02182747, -0.02595685, ...,  0.00902402,\n",
       "         0.03318946,  0.01438079],\n",
       "       ...,\n",
       "       [-0.03041965,  0.01002558,  0.03144941, ...,  0.01759308,\n",
       "         0.02555424,  0.01308179],\n",
       "       [-0.00215481,  0.01847753,  0.0111186 , ..., -0.03004795,\n",
       "         0.01075993, -0.03022461],\n",
       "       [-0.01584445, -0.01495346,  0.01423285, ...,  0.01149589,\n",
       "         0.02739929, -0.0087856 ]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp2_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_layer_4_tf[:,:,0,0] == reshaped_layer_4_th[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.3667248e-02,  1.1791922e-02, -1.5521424e-02, -2.9741099e-02,\n",
       "        -3.2523800e-02,  1.4626086e-02,  1.2047417e-02],\n",
       "       [-2.4339147e-03, -3.1263407e-02, -1.3361754e-02,  4.4008680e-03,\n",
       "        -1.9189849e-02, -7.3245205e-03, -2.6377063e-02],\n",
       "       [ 2.2111367e-02, -3.1224404e-02, -1.6263053e-02,  7.7389181e-05,\n",
       "        -1.9530669e-02,  1.2474399e-02,  7.2748102e-03],\n",
       "       [ 4.1123554e-03, -8.4859487e-03,  3.3640474e-02,  3.3443376e-02,\n",
       "        -1.4399737e-03,  2.7262919e-02, -2.6372895e-03],\n",
       "       [ 6.2220804e-03,  5.4944009e-03,  2.1667164e-02, -2.7836967e-02,\n",
       "        -3.3434503e-02,  2.6999999e-02, -1.1504609e-02],\n",
       "       [ 2.5001474e-02,  2.1872666e-02,  1.1878926e-02, -2.1264255e-02,\n",
       "        -9.3361419e-03, -1.6122777e-02,  1.5861399e-02],\n",
       "       [ 2.4418727e-02,  2.8766371e-02,  2.0588916e-02, -1.5329404e-02,\n",
       "         1.9880321e-02,  2.9752910e-02, -2.3275729e-02]], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_layer_4_tf[:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03366725,  0.00843545,  0.01274306, -0.01319763, -0.01539183,\n",
       "        -0.03327732,  0.02398875],\n",
       "       [ 0.00142732,  0.02283858,  0.01123451, -0.00888788,  0.02657335,\n",
       "        -0.00162866, -0.00573828],\n",
       "       [-0.02683809,  0.02705957,  0.01692493,  0.00764678, -0.01690764,\n",
       "        -0.02633323, -0.03011203],\n",
       "       [ 0.02323712, -0.01751038, -0.01486759,  0.0044138 , -0.0014921 ,\n",
       "        -0.03331087, -0.02846824],\n",
       "       [-0.02815644,  0.00241011, -0.0010077 ,  0.02428937, -0.0067814 ,\n",
       "        -0.02011822, -0.00022816],\n",
       "       [-0.02490951, -0.01180885,  0.00921149,  0.02398837,  0.01401584,\n",
       "         0.0121631 , -0.00961414],\n",
       "       [-0.01658495,  0.01327209, -0.00641046,  0.02560753,  0.02371763,\n",
       "         0.0305793 , -0.03181244]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_layer_4_th[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose().permute(3,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(weights_layer_4)):\n",
    "    for j in range(len(weights_layer_4)):\n",
    "        comparison = weights_layer_4[i] == leaf_weights_layer_4[j].numpy()\n",
    "        if (comparison.all()):\n",
    "            print(i, \"-->\", j)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[a, b]\n",
    " [c, d]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(10, 50) #10, 5\n",
    "y = x.transpose() #5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False False False]\n",
      " [False False False False False]\n",
      " [False False False False False]\n",
      " [False  True False False False]\n",
      " [False False False False False]]\n",
      "x_reshaped\n",
      "[[0.8381639198 0.4161102807 0.1994478473 0.7831800801 0.8313528369]\n",
      " [0.6246692627 0.1743852513 0.7492047847 0.4822756918 0.2626059972]\n",
      " [0.9425990288 0.363140734  0.8320840698 0.8834993906 0.6796215273]\n",
      " [0.4433552718 0.5345840542 0.5567759046 0.8552684374 0.469350499 ]\n",
      " [0.884944586  0.9791536883 0.3130908692 0.1584972722 0.9696954475]]\n",
      "y_reshaped first filter:\n",
      "[[0.8381639198 0.9425990288 0.884944586  0.6710914297 0.5996697948]\n",
      " [0.1994478473 0.8320840698 0.3130908692 0.7058134381 0.6522678065]\n",
      " [0.8313528369 0.6796215273 0.9696954475 0.8257342263 0.6421942309]\n",
      " [0.1743852513 0.5345840542 0.2449954859 0.7732865204 0.5530661602]\n",
      " [0.4822756918 0.8552684374 0.6167653769 0.1594214429 0.7069830247]]\n"
     ]
    }
   ],
   "source": [
    "x_reshaped = x.reshape(10, 2, 5, 5)\n",
    "y_reshaped = y.reshape(5, 5, 2, 10).transpose(1, 0, 2, 3)\n",
    "\n",
    "np.set_printoptions(precision=10)\n",
    "\n",
    "print(x_reshaped[0,0,:,:] == y_reshaped[:,:,0,0])\n",
    "\n",
    "print('x_reshaped')\n",
    "print(x_reshaped[0,0,:,:])\n",
    "\n",
    "print('y_reshaped first filter:')\n",
    "print(y_reshaped[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3668262076, 0.4825731703, 0.4885014324, 0.2731217713,\n",
       "        0.8529312591, 0.0122788547, 0.9711647569, 0.5497323823,\n",
       "        0.7476286153, 0.6447445487],\n",
       "       [0.4690085275, 0.9362824227, 0.4266285632, 0.7267193019,\n",
       "        0.7003179305, 0.1817239042, 0.4780344558, 0.1682903773,\n",
       "        0.8459031626, 0.40326962  ],\n",
       "       [0.980170773 , 0.3766404503, 0.9306496499, 0.7449403453,\n",
       "        0.3722865803, 0.7230892627, 0.3421237652, 0.8352796869,\n",
       "        0.8374246459, 0.2712513183],\n",
       "       [0.2623451506, 0.6541574898, 0.9522122811, 0.7769780296,\n",
       "        0.8473281613, 0.5156848037, 0.4478182475, 0.9144557135,\n",
       "        0.9540844006, 0.8499903664],\n",
       "       [0.5703400117, 0.6828153847, 0.1157582805, 0.2369616003,\n",
       "        0.146474764 , 0.7064216708, 0.5591952862, 0.5185316104,\n",
       "        0.9500004283, 0.0829667578],\n",
       "       [0.6089536945, 0.6375651296, 0.1234536609, 0.3803547185,\n",
       "        0.4363032671, 0.098980711 , 0.9650800389, 0.8217236826,\n",
       "        0.5305508439, 0.441931051 ],\n",
       "       [0.723476543 , 0.4795700683, 0.8033154895, 0.109109587 ,\n",
       "        0.7569124426, 0.6211700046, 0.1716677691, 0.2783141126,\n",
       "        0.9442782261, 0.0037387307],\n",
       "       [0.9145863113, 0.6985345219, 0.292657085 , 0.7049788804,\n",
       "        0.4030903468, 0.6346565451, 0.2298333789, 0.7702055656,\n",
       "        0.0634078995, 0.3132701952],\n",
       "       [0.1987380143, 0.8735787425, 0.1346375602, 0.2617170717,\n",
       "        0.6751712578, 0.8427922512, 0.973890461 , 0.3450769204,\n",
       "        0.0263454772, 0.7589770051],\n",
       "       [0.5435334497, 0.6239227284, 0.0980682691, 0.007688415 ,\n",
       "        0.1343349539, 0.7131073955, 0.9097238459, 0.9873599146,\n",
       "        0.897205052 , 0.7807443196]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3668262076, 0.4690085275, 0.980170773 , 0.2623451506,\n",
       "        0.5703400117, 0.6089536945, 0.723476543 , 0.9145863113,\n",
       "        0.1987380143, 0.5435334497],\n",
       "       [0.4825731703, 0.9362824227, 0.3766404503, 0.6541574898,\n",
       "        0.6828153847, 0.6375651296, 0.4795700683, 0.6985345219,\n",
       "        0.8735787425, 0.6239227284],\n",
       "       [0.4885014324, 0.4266285632, 0.9306496499, 0.9522122811,\n",
       "        0.1157582805, 0.1234536609, 0.8033154895, 0.292657085 ,\n",
       "        0.1346375602, 0.0980682691],\n",
       "       [0.2731217713, 0.7267193019, 0.7449403453, 0.7769780296,\n",
       "        0.2369616003, 0.3803547185, 0.109109587 , 0.7049788804,\n",
       "        0.2617170717, 0.007688415 ],\n",
       "       [0.8529312591, 0.7003179305, 0.3722865803, 0.8473281613,\n",
       "        0.146474764 , 0.4363032671, 0.7569124426, 0.4030903468,\n",
       "        0.6751712578, 0.1343349539],\n",
       "       [0.0122788547, 0.1817239042, 0.7230892627, 0.5156848037,\n",
       "        0.7064216708, 0.098980711 , 0.6211700046, 0.6346565451,\n",
       "        0.8427922512, 0.7131073955],\n",
       "       [0.9711647569, 0.4780344558, 0.3421237652, 0.4478182475,\n",
       "        0.5591952862, 0.9650800389, 0.1716677691, 0.2298333789,\n",
       "        0.973890461 , 0.9097238459],\n",
       "       [0.5497323823, 0.1682903773, 0.8352796869, 0.9144557135,\n",
       "        0.5185316104, 0.8217236826, 0.2783141126, 0.7702055656,\n",
       "        0.3450769204, 0.9873599146],\n",
       "       [0.7476286153, 0.8459031626, 0.8374246459, 0.9540844006,\n",
       "        0.9500004283, 0.5305508439, 0.9442782261, 0.0634078995,\n",
       "        0.0263454772, 0.897205052 ],\n",
       "       [0.6447445487, 0.40326962  , 0.2712513183, 0.8499903664,\n",
       "        0.0829667578, 0.441931051 , 0.0037387307, 0.3132701952,\n",
       "        0.7589770051, 0.7807443196]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False, False]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[4.8742943125e-01, 3.4029038861e-01, 7.9780543861e-01,\n",
       "          3.6600781624e-01, 9.2931479526e-01],\n",
       "         [2.2531079332e-01, 2.7968934481e-01, 4.7936365409e-01,\n",
       "          8.0498228614e-01, 2.1918377528e-01],\n",
       "         [6.7403038945e-01, 7.3936941750e-01, 7.4931434901e-01,\n",
       "          8.7626828478e-01, 3.2585093742e-01],\n",
       "         [8.1022346800e-01, 5.7718645685e-01, 8.4281626962e-01,\n",
       "          5.5476069821e-01, 4.3112244225e-01],\n",
       "         [9.6575219429e-04, 1.7826002035e-03, 6.0169479264e-01,\n",
       "          1.9269183004e-01, 8.9772395583e-01]],\n",
       "\n",
       "        [[2.5007604245e-01, 7.9675493100e-01, 7.6172691749e-01,\n",
       "          7.4801940999e-01, 7.9799074357e-01],\n",
       "         [3.6911353868e-01, 7.1530257322e-01, 3.1842481049e-01,\n",
       "          3.0918370555e-01, 4.8375925017e-01],\n",
       "         [2.1272098622e-01, 6.2916032630e-01, 1.2147648053e-02,\n",
       "          5.2247437488e-01, 6.3418485414e-01],\n",
       "         [3.3590675465e-01, 5.9011714230e-01, 4.9847812919e-01,\n",
       "          3.2097833140e-01, 4.3013098707e-02],\n",
       "         [2.3022374808e-01, 3.5057108620e-01, 2.8376057261e-01,\n",
       "          4.5041604023e-01, 5.3077514747e-01]]],\n",
       "\n",
       "\n",
       "       [[[1.2680853367e-01, 7.8115495131e-01, 7.7033800979e-01,\n",
       "          9.9150200816e-01, 8.0655999496e-01],\n",
       "         [4.9885640955e-01, 2.8490001122e-01, 6.6734714678e-01,\n",
       "          8.4383955086e-01, 7.0572796903e-01],\n",
       "         [8.1493398954e-01, 6.4796724026e-01, 6.0538071125e-01,\n",
       "          4.6039551867e-01, 8.3612064375e-01],\n",
       "         [2.1882965396e-01, 6.7014744944e-01, 4.5286584281e-02,\n",
       "          5.5975463027e-01, 1.3068630175e-01],\n",
       "         [3.1910915275e-01, 8.1296422282e-01, 3.7386182156e-01,\n",
       "          2.5717506603e-01, 2.8347737884e-01]],\n",
       "\n",
       "        [[5.8727199751e-01, 2.7547101462e-02, 3.8615845507e-01,\n",
       "          4.7954549609e-01, 1.3819208856e-01],\n",
       "         [7.4484782850e-01, 3.1604889436e-01, 9.5911175185e-01,\n",
       "          7.2481201123e-01, 1.7483724620e-01],\n",
       "         [4.0146476166e-01, 4.5963390996e-01, 3.3119438773e-01,\n",
       "          5.1334804669e-01, 3.6480729226e-01],\n",
       "         [2.6514108882e-01, 8.2888827915e-01, 7.6545479060e-01,\n",
       "          2.6546947824e-01, 9.2099692480e-02],\n",
       "         [4.7868731081e-01, 8.3536174759e-01, 8.4336579509e-01,\n",
       "          8.7039156489e-01, 3.9462458838e-01]]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[4.8742943125e-01, 6.7403038945e-01],\n",
       "         [9.6575219429e-04, 3.6911353868e-01]],\n",
       "\n",
       "        [[3.3590675465e-01, 1.2680853367e-01],\n",
       "         [8.1493398954e-01, 3.1910915275e-01]],\n",
       "\n",
       "        [[7.4484782850e-01, 2.6514108882e-01],\n",
       "         [3.4029038861e-01, 7.3936941750e-01]],\n",
       "\n",
       "        [[1.7826002035e-03, 7.1530257322e-01],\n",
       "         [5.9011714230e-01, 7.8115495131e-01]],\n",
       "\n",
       "        [[6.4796724026e-01, 8.1296422282e-01],\n",
       "         [3.1604889436e-01, 8.2888827915e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.9780543861e-01, 7.4931434901e-01],\n",
       "         [6.0169479264e-01, 3.1842481049e-01]],\n",
       "\n",
       "        [[4.9847812919e-01, 7.7033800979e-01],\n",
       "         [6.0538071125e-01, 3.7386182156e-01]],\n",
       "\n",
       "        [[9.5911175185e-01, 7.6545479060e-01],\n",
       "         [3.6600781624e-01, 8.7626828478e-01]],\n",
       "\n",
       "        [[1.9269183004e-01, 3.0918370555e-01],\n",
       "         [3.2097833140e-01, 9.9150200816e-01]],\n",
       "\n",
       "        [[4.6039551867e-01, 2.5717506603e-01],\n",
       "         [7.2481201123e-01, 2.6546947824e-01]]],\n",
       "\n",
       "\n",
       "       [[[9.2931479526e-01, 3.2585093742e-01],\n",
       "         [8.9772395583e-01, 4.8375925017e-01]],\n",
       "\n",
       "        [[4.3013098707e-02, 8.0655999496e-01],\n",
       "         [8.3612064375e-01, 2.8347737884e-01]],\n",
       "\n",
       "        [[1.7483724620e-01, 9.2099692480e-02],\n",
       "         [2.2531079332e-01, 8.1022346800e-01]],\n",
       "\n",
       "        [[2.5007604245e-01, 2.1272098622e-01],\n",
       "         [2.3022374808e-01, 4.9885640955e-01]],\n",
       "\n",
       "        [[2.1882965396e-01, 5.8727199751e-01],\n",
       "         [4.0146476166e-01, 4.7868731081e-01]]],\n",
       "\n",
       "\n",
       "       [[[2.7968934481e-01, 5.7718645685e-01],\n",
       "         [7.9675493100e-01, 6.2916032630e-01]],\n",
       "\n",
       "        [[3.5057108620e-01, 2.8490001122e-01],\n",
       "         [6.7014744944e-01, 2.7547101462e-02]],\n",
       "\n",
       "        [[4.5963390996e-01, 8.3536174759e-01],\n",
       "         [4.7936365409e-01, 8.4281626962e-01]],\n",
       "\n",
       "        [[7.6172691749e-01, 1.2147648053e-02],\n",
       "         [2.8376057261e-01, 6.6734714678e-01]],\n",
       "\n",
       "        [[4.5286584281e-02, 3.8615845507e-01],\n",
       "         [3.3119438773e-01, 8.4336579509e-01]]],\n",
       "\n",
       "\n",
       "       [[[8.0498228614e-01, 5.5476069821e-01],\n",
       "         [7.4801940999e-01, 5.2247437488e-01]],\n",
       "\n",
       "        [[4.5041604023e-01, 8.4383955086e-01],\n",
       "         [5.5975463027e-01, 4.7954549609e-01]],\n",
       "\n",
       "        [[5.1334804669e-01, 8.7039156489e-01],\n",
       "         [2.1918377528e-01, 4.3112244225e-01]],\n",
       "\n",
       "        [[7.9799074357e-01, 6.3418485414e-01],\n",
       "         [5.3077514747e-01, 7.0572796903e-01]],\n",
       "\n",
       "        [[1.3068630175e-01, 1.3819208856e-01],\n",
       "         [3.6480729226e-01, 3.9462458838e-01]]]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8742943125e-01, 3.4029038861e-01, 7.9780543861e-01,\n",
       "        3.6600781624e-01, 9.2931479526e-01, 2.2531079332e-01,\n",
       "        2.7968934481e-01, 4.7936365409e-01, 8.0498228614e-01,\n",
       "        2.1918377528e-01],\n",
       "       [6.7403038945e-01, 7.3936941750e-01, 7.4931434901e-01,\n",
       "        8.7626828478e-01, 3.2585093742e-01, 8.1022346800e-01,\n",
       "        5.7718645685e-01, 8.4281626962e-01, 5.5476069821e-01,\n",
       "        4.3112244225e-01],\n",
       "       [9.6575219429e-04, 1.7826002035e-03, 6.0169479264e-01,\n",
       "        1.9269183004e-01, 8.9772395583e-01, 2.5007604245e-01,\n",
       "        7.9675493100e-01, 7.6172691749e-01, 7.4801940999e-01,\n",
       "        7.9799074357e-01],\n",
       "       [3.6911353868e-01, 7.1530257322e-01, 3.1842481049e-01,\n",
       "        3.0918370555e-01, 4.8375925017e-01, 2.1272098622e-01,\n",
       "        6.2916032630e-01, 1.2147648053e-02, 5.2247437488e-01,\n",
       "        6.3418485414e-01],\n",
       "       [3.3590675465e-01, 5.9011714230e-01, 4.9847812919e-01,\n",
       "        3.2097833140e-01, 4.3013098707e-02, 2.3022374808e-01,\n",
       "        3.5057108620e-01, 2.8376057261e-01, 4.5041604023e-01,\n",
       "        5.3077514747e-01],\n",
       "       [1.2680853367e-01, 7.8115495131e-01, 7.7033800979e-01,\n",
       "        9.9150200816e-01, 8.0655999496e-01, 4.9885640955e-01,\n",
       "        2.8490001122e-01, 6.6734714678e-01, 8.4383955086e-01,\n",
       "        7.0572796903e-01],\n",
       "       [8.1493398954e-01, 6.4796724026e-01, 6.0538071125e-01,\n",
       "        4.6039551867e-01, 8.3612064375e-01, 2.1882965396e-01,\n",
       "        6.7014744944e-01, 4.5286584281e-02, 5.5975463027e-01,\n",
       "        1.3068630175e-01],\n",
       "       [3.1910915275e-01, 8.1296422282e-01, 3.7386182156e-01,\n",
       "        2.5717506603e-01, 2.8347737884e-01, 5.8727199751e-01,\n",
       "        2.7547101462e-02, 3.8615845507e-01, 4.7954549609e-01,\n",
       "        1.3819208856e-01],\n",
       "       [7.4484782850e-01, 3.1604889436e-01, 9.5911175185e-01,\n",
       "        7.2481201123e-01, 1.7483724620e-01, 4.0146476166e-01,\n",
       "        4.5963390996e-01, 3.3119438773e-01, 5.1334804669e-01,\n",
       "        3.6480729226e-01],\n",
       "       [2.6514108882e-01, 8.2888827915e-01, 7.6545479060e-01,\n",
       "        2.6546947824e-01, 9.2099692480e-02, 4.7868731081e-01,\n",
       "        8.3536174759e-01, 8.4336579509e-01, 8.7039156489e-01,\n",
       "        3.9462458838e-01]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8742943125e-01, 6.7403038945e-01, 9.6575219429e-04,\n",
       "        3.6911353868e-01, 3.3590675465e-01, 1.2680853367e-01,\n",
       "        8.1493398954e-01, 3.1910915275e-01, 7.4484782850e-01,\n",
       "        2.6514108882e-01],\n",
       "       [3.4029038861e-01, 7.3936941750e-01, 1.7826002035e-03,\n",
       "        7.1530257322e-01, 5.9011714230e-01, 7.8115495131e-01,\n",
       "        6.4796724026e-01, 8.1296422282e-01, 3.1604889436e-01,\n",
       "        8.2888827915e-01],\n",
       "       [7.9780543861e-01, 7.4931434901e-01, 6.0169479264e-01,\n",
       "        3.1842481049e-01, 4.9847812919e-01, 7.7033800979e-01,\n",
       "        6.0538071125e-01, 3.7386182156e-01, 9.5911175185e-01,\n",
       "        7.6545479060e-01],\n",
       "       [3.6600781624e-01, 8.7626828478e-01, 1.9269183004e-01,\n",
       "        3.0918370555e-01, 3.2097833140e-01, 9.9150200816e-01,\n",
       "        4.6039551867e-01, 2.5717506603e-01, 7.2481201123e-01,\n",
       "        2.6546947824e-01],\n",
       "       [9.2931479526e-01, 3.2585093742e-01, 8.9772395583e-01,\n",
       "        4.8375925017e-01, 4.3013098707e-02, 8.0655999496e-01,\n",
       "        8.3612064375e-01, 2.8347737884e-01, 1.7483724620e-01,\n",
       "        9.2099692480e-02],\n",
       "       [2.2531079332e-01, 8.1022346800e-01, 2.5007604245e-01,\n",
       "        2.1272098622e-01, 2.3022374808e-01, 4.9885640955e-01,\n",
       "        2.1882965396e-01, 5.8727199751e-01, 4.0146476166e-01,\n",
       "        4.7868731081e-01],\n",
       "       [2.7968934481e-01, 5.7718645685e-01, 7.9675493100e-01,\n",
       "        6.2916032630e-01, 3.5057108620e-01, 2.8490001122e-01,\n",
       "        6.7014744944e-01, 2.7547101462e-02, 4.5963390996e-01,\n",
       "        8.3536174759e-01],\n",
       "       [4.7936365409e-01, 8.4281626962e-01, 7.6172691749e-01,\n",
       "        1.2147648053e-02, 2.8376057261e-01, 6.6734714678e-01,\n",
       "        4.5286584281e-02, 3.8615845507e-01, 3.3119438773e-01,\n",
       "        8.4336579509e-01],\n",
       "       [8.0498228614e-01, 5.5476069821e-01, 7.4801940999e-01,\n",
       "        5.2247437488e-01, 4.5041604023e-01, 8.4383955086e-01,\n",
       "        5.5975463027e-01, 4.7954549609e-01, 5.1334804669e-01,\n",
       "        8.7039156489e-01],\n",
       "       [2.1918377528e-01, 4.3112244225e-01, 7.9799074357e-01,\n",
       "        6.3418485414e-01, 5.3077514747e-01, 7.0572796903e-01,\n",
       "        1.3068630175e-01, 1.3819208856e-01, 3.6480729226e-01,\n",
       "        3.9462458838e-01]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(64, 7, 7)\n",
    "\n",
    "[[49] + [49] + [49]]\n",
    "\n",
    "\n",
    "[0, 5, 20 ... ]\n",
    "\n",
    "[0:49, 5]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
